2020-05-10 10:52:23 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: weibo)
2020-05-10 10:52:23 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 18.7.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17134-SP0
2020-05-10 10:52:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'logs\\weibo\\weibofilm\\3a7c3c8c926911ea803d34f39a004e9c.log', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2020-05-10 10:52:23 [scrapy.middleware] WARNING: Disabled TelnetConsole: TELNETCONSOLE_ENABLED setting is True but required twisted modules failed to import:
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\extensions\telnet.py", line 15, in <module>
    from twisted.conch import manhole, telnet
  File "e:\software\python3.7.6\lib\site-packages\twisted\conch\manhole.py", line 154
    def write(self, data, async=False):
                              ^
SyntaxError: invalid syntax

2020-05-10 10:52:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats', 'scrapy.extensions.logstats.LogStats']
2020-05-10 10:52:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": []}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": []}}}
2020-05-10 10:52:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:60001
2020-05-10 10:52:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session HTTP/1.1" 200 830
2020-05-10 10:52:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:52:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/quicklogin?r=https%3A%2F%2Fm.weibo.cn%2Fdetail%2F4375850843355381", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:52:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:52:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:52:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/element {"using": "xpath", "value": ".//li[@class = 'l-uitem']/a", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:52:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/element HTTP/1.1" 200 103
2020-05-10 10:52:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:52:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "arguments[0].click();", "args": [{"ELEMENT": "0.34570225145193434-1", "element-6066-11e4-a52e-4f735466cecf": "0.34570225145193434-1"}], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:52:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:52:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:52:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/element {"using": "xpath", "value": ".//iframe[@id = 'ptlogin_iframe']", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:52:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/element HTTP/1.1" 200 101
2020-05-10 10:52:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:52:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/frame {"id": {"ELEMENT": "0.037383159369206-1", "element-6066-11e4-a52e-4f735466cecf": "0.037383159369206-1"}, "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:52:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/frame HTTP/1.1" 200 72
2020-05-10 10:52:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:52:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/element {"using": "xpath", "value": ".//span[@id = 'img_out_1194380923']", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:52:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/element HTTP/1.1" 200 102
2020-05-10 10:52:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:52:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "arguments[0].click();", "args": [{"ELEMENT": "0.9427863665051119-1", "element-6066-11e4-a52e-4f735466cecf": "0.9427863665051119-1"}], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:52:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:52:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:52:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-10 10:52:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-10 10:52:46 [scrapy.middleware] INFO: Enabled item pipelines:
['weibo.pipelines.WeiboPipeline']
2020-05-10 10:52:46 [scrapy.core.engine] INFO: Spider opened
2020-05-10 10:52:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-10 10:52:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4407406534155151> (referer: None)
2020-05-10 10:52:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4450560629813885> (referer: None)
2020-05-10 10:52:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4451216975240885> (referer: None)
2020-05-10 10:52:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4407406534155151", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:53:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 90243
2020-05-10 10:53:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 90243
2020-05-10 10:53:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 124095
2020-05-10 10:53:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 157199
2020-05-10 10:53:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=14000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 188077
2020-05-10 10:53:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=17500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 221843
2020-05-10 10:53:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=21000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:29 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 241659
2020-05-10 10:53:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=24500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:31 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 243583
2020-05-10 10:53:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=28000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 249929
2020-05-10 10:53:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=31500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:35 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 262611
2020-05-10 10:53:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=35000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 275524
2020-05-10 10:53:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=38500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:40 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 289103
2020-05-10 10:53:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=42000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 292327
2020-05-10 10:53:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=45500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:53:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 292327
2020-05-10 10:53:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 292327
2020-05-10 10:53:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '失败是因为有些能人被埋没了，应该让他们来拍。',
 'essay_id': 0,
 'fav_nums': '28',
 'label': '上海堡垒',
 'score': 0.1478,
 'type': 'neg',
 'user': '夏泥巴家篱笆下的泥巴'}
2020-05-10 10:53:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4472312441480226> (referer: None)
2020-05-10 10:53:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4445727071305724> (failed 1 times): 502 Bad Gateway
2020-05-10 10:53:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4406931189701602> (referer: None)
2020-05-10 10:53:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4471517670934362> (referer: None)
2020-05-10 10:53:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4407115298681076> (referer: None)
2020-05-10 10:53:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405927283314667> (referer: None)
2020-05-10 10:53:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4446182220666437> (referer: None)
2020-05-10 10:53:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4453795063054257> (failed 1 times): 502 Bad Gateway
2020-05-10 10:53:48 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 1 items (at 1 items/min)
2020-05-10 10:53:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '不仅仅是鹿晗的锅，剧本确实差，而且导演真的不行。只是鹿晗是流量么，个个拿着人家骂',
 'essay_id': 0,
 'fav_nums': '28',
 'label': '上海堡垒',
 'score': 0.1583,
 'type': 'neg',
 'user': '好好学习MAX'}
2020-05-10 10:53:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4450560629813885", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:53:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 62546
2020-05-10 10:53:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 62546
2020-05-10 10:53:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-18',
 'content': '高，还好吗？',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8008,
 'type': 'pos',
 'user': 'Sydneysunny'}
2020-05-10 10:53:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4451216975240885", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:53:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 48389
2020-05-10 10:53:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:53:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:53:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 48389
2020-05-10 10:53:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4451216975240885>
{'add_time': '2019-12-19',
 'content': '恭喜你的优质内容进入热门流电影频道曝光~持续沿着垂直领域方向创作，获取更多流量,详情见',
 'essay_id': 87,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9999,
 'type': 'pos',
 'user': '微博电影'}
2020-05-10 10:54:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '缺少一个铁血男主角',
 'essay_id': 0,
 'fav_nums': '23',
 'label': '上海堡垒',
 'score': 0.9543,
 'type': 'pos',
 'user': '循环播放打鼾声防盗'}
2020-05-10 10:54:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4472312441480226", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:54:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:04 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 50272
2020-05-10 10:54:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:04 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 50272
2020-05-10 10:54:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4472312441480226>
{'add_time': '2-15 20:07',
 'content': '这个BGM是什么',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '百里守约的日子'}
2020-05-10 10:54:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4406931189701602", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:54:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 96182
2020-05-10 10:54:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:11 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 96182
2020-05-10 10:54:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:11 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:13 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 134826
2020-05-10 10:54:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 172437
2020-05-10 10:54:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 172437
2020-05-10 10:54:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '沈阳有嘛 ',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.7188,
 'type': 'pos',
 'user': '_橘子味的摩羯座'}
2020-05-10 10:54:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4471517670934362", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:54:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 262005
2020-05-10 10:54:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 262005
2020-05-10 10:54:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-20',
 'content': '可爱又真实的G',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.947,
 'type': 'pos',
 'user': '_____李小酸'}
2020-05-10 10:54:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4407115298681076", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:54:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:27 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 93270
2020-05-10 10:54:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:27 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 93270
2020-05-10 10:54:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:30 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 131760
2020-05-10 10:54:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 168546
2020-05-10 10:54:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=14000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:34 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 209367
2020-05-10 10:54:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=17500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:36 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 209353
2020-05-10 10:54:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:36 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 209353
2020-05-10 10:54:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '感谢大吧，那什么',
 'essay_id': 0,
 'fav_nums': '181',
 'label': '上海堡垒',
 'score': 0.6961,
 'type': 'pos',
 'user': '江户川木风'}
2020-05-10 10:54:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405927283314667", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:54:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 87117
2020-05-10 10:54:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 87117
2020-05-10 10:54:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 124589
2020-05-10 10:54:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 155841
2020-05-10 10:54:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=14000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 197756
2020-05-10 10:54:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=17500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:54:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 204091
2020-05-10 10:54:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 204091
2020-05-10 10:54:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '想为这样的小江承包整片郁金香海洋，和所有夜晚的“好好睡，晚安”',
 'essay_id': 0,
 'fav_nums': '63',
 'label': '上海堡垒',
 'score': 0.4706,
 'type': 'neg',
 'user': '鹿晗吧_LuhanBar'}
2020-05-10 10:54:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4446182220666437", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:54:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 53007
2020-05-10 10:54:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:54:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 53007
2020-05-10 10:54:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:54:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4446182220666437>
{'add_time': '2019-12-5',
 'content': 'Hi~您好，您发布的文章已被创建同名问题，文章内容被收录为回答。此问题将会吸引更多用户参与讨论，您的文章也会被更多网友看到，带来更高曝光和互动量~戳→→',
 'essay_id': 28,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9846,
 'type': 'pos',
 'user': '微博问答'}
2020-05-10 10:54:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '武汉保利星河九州粗暴对待业主！不仅虚假承诺还不让业主看样板间！',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.0307,
 'type': 'neg',
 'user': '杨穆穆大小姐'}
2020-05-10 10:55:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4472312441480226>
{'add_time': '2-16 18:25',
 'content': '？？？',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.092,
 'type': 'neg',
 'user': '银色满际时'}
2020-05-10 10:55:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': ' 迟到的大连包场  但我们的热情永远不会迟到',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.9892,
 'type': 'pos',
 'user': '冰美式ing'}
2020-05-10 10:55:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-18',
 'content': '喜欢害羞的你',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6769,
 'type': 'pos',
 'user': 'MinnieChing'}
2020-05-10 10:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '能不能积极一点 打打鸡血 进度每三小时发条微博 定个目标 别再低调了',
 'essay_id': 0,
 'fav_nums': '121',
 'label': '上海堡垒',
 'score': 0.769,
 'type': 'pos',
 'user': '他的眉上痣'}
2020-05-10 10:55:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 16 items (at 15 items/min)
2020-05-10 10:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '我来了!',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '_清酒白茶_Liquor'}
2020-05-10 10:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-21',
 'content': '虽不是鹿晗的铁粉，但话还是要说的，上映前，他们俩一起去拍了“向往的生活”，说鹿晗怎么怎么好，剧本没出来就定了，就觉得他适合这部戏，期间还推杯换盏的，开心的飞起，感觉看到了票房大卖的样子，现在呢，最起码总结电影问题的时候不应该单独拎某个人出来，给世人传递意念。导演这点不好！',
 'essay_id': 0,
 'fav_nums': '11',
 'label': '上海堡垒',
 'score': 0.9983,
 'type': 'pos',
 'user': '开心大大全全'}
2020-05-10 10:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '辛苦辛苦，天气原因延迟到今天，但是依然热情高涨[加油][加油][加油]',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9999,
 'type': 'pos',
 'user': '傻蛋鹿'}
2020-05-10 10:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4187122258228984> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4336066754827248> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4383519922827650> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4187122292937189> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4336063729978447> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4402012919971507> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4386288000091686> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:55:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4336330416371642> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-18',
 'content': '太温柔',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.7124,
 'type': 'pos',
 'user': '芦苇高高'}
2020-05-10 10:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '真想陪他闯天下就把该做好的事做好。没有哪家搞集资是低调就能搞好的，已经数次尝试理解大吧了，可还是会为大吧的工作效率感到失望。鹿晗这张专辑销量有多重要大吧难道不明白吗？可为什么我看不到大吧的积极性？',
 'essay_id': 0,
 'fav_nums': '113',
 'label': '上海堡垒',
 'score': 0.0442,
 'type': 'neg',
 'user': '滑行浣熊不倒翁'}
2020-05-10 10:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '战吾鹿t'}
2020-05-10 10:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '觉得不会投，因为个人觉得，这个导演太厉害了，不得不佩服，被向佐说',
 'essay_id': 0,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.2504,
 'type': 'neg',
 'user': '梁晓彤'}
2020-05-10 10:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '天辽地宁，与鹿同行',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.1395,
 'type': 'neg',
 'user': '小小小小4er'}
2020-05-10 10:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'Moon6便士'}
2020-05-10 10:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '为什么大吧对于新专辑好像一点都不重视的样子，不能对鹿晗的新专辑上心一点吗，别家要出新专辑了，官方后援会每天都积极让粉丝为新专辑努力，到了这里就是低调',
 'essay_id': 0,
 'fav_nums': '44',
 'label': '上海堡垒',
 'score': 0.9441,
 'type': 'pos',
 'user': 'Adelinehu827'}
2020-05-10 10:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'M7鹿小鼠'}
2020-05-10 10:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '明星还是很重要的.哪怕剧本烂，很多人还是会冲着明星去.所以鹿晗这样的影响力还不足以当主角撑起一部电影的.',
 'essay_id': 0,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.9998,
 'type': 'pos',
 'user': '养了一只大金毛'}
2020-05-10 10:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '天辽地宁与鹿同行',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.1395,
 'type': 'neg',
 'user': 'Yimi半半-'}
2020-05-10 10:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-18',
 'content': '💔',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': 'Missna_'}
2020-05-10 10:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦啦。百度鹿晗吧，陪你闯天下！💛',
 'essay_id': 0,
 'fav_nums': '35',
 'label': '上海堡垒',
 'score': 0.7861,
 'type': 'pos',
 'user': '意中人是阿鹿'}
2020-05-10 10:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '转发微博',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.6439,
 'type': 'pos',
 'user': 'M芋头M'}
2020-05-10 10:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '其实我觉得还可以.....特效做的很好呀',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.7964,
 'type': 'pos',
 'user': '爸爸有只鸡'}
2020-05-10 10:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '棒棒哒，加油！',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.8851,
 'type': 'pos',
 'user': '鹿家男饭灵夏i'}
2020-05-10 10:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-18',
 'content': '怎么奇怪',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.3169,
 'type': 'neg',
 'user': '生物钟720'}
2020-05-10 10:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '陪你闯天下',
 'essay_id': 0,
 'fav_nums': '18',
 'label': '上海堡垒',
 'score': 0.577,
 'type': 'pos',
 'user': '筱晚芊芊'}
2020-05-10 10:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '很喜欢很棒',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9614,
 'type': 'pos',
 'user': 'L燕子林深处迷鹿77'}
2020-05-10 10:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '在那个“向往的生活”里面，你那个导演不是说就看了鹿晗那张照片，就觉得该是他吗？现在又说这样的号，未免太那个了。我记得当时，黄磊还问那个导演（导演名字记不得）是不是看鹿晗好看，那个导演还说不是，是真的很看好他什么来着，哎，我都不知道说什么了，我都不是鹿晗的粉，都看不过去',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.8787,
 'type': 'pos',
 'user': '茉朦来生想做一只猫'}
2020-05-10 10:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-20',
 'content': '天气原因才看上，感谢你们的一鹿相伴',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5518,
 'type': 'pos',
 'user': 'LH7孟孟LH7'}
2020-05-10 10:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-18',
 'content': 'miss u',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2784,
 'type': 'neg',
 'user': 'MinnieChing'}
2020-05-10 10:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '请问评论里说大吧不积极的都给了多少钱呢',
 'essay_id': 0,
 'fav_nums': '15',
 'label': '上海堡垒',
 'score': 0.0021,
 'type': 'neg',
 'user': 'SunnYyuTongG'}
2020-05-10 10:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '很棒很棒',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.9736,
 'type': 'pos',
 'user': 'Quiana_Ma'}
2020-05-10 10:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '剧本＞导演＞演员',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.9778,
 'type': 'pos',
 'user': '枭花堂'}
2020-05-10 10:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '闽闽之中，豫芦相逢，天地辽宁，咔咔的',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9992,
 'type': 'pos',
 'user': '鹿的大白兔'}
2020-05-10 10:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4450560629813885>
{'add_time': '2019-12-18',
 'content': '爱你❤',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.728,
 'type': 'pos',
 'user': 'Hequn群群'}
2020-05-10 10:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': ' 好棒',
 'essay_id': 0,
 'fav_nums': '14',
 'label': '上海堡垒',
 'score': 0.875,
 'type': 'pos',
 'user': 'y11y77y'}
2020-05-10 10:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '江洋宝贝',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8161,
 'type': 'pos',
 'user': 'Ida哒哒哒哒哒哒'}
2020-05-10 10:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '有个错别字，取得',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5556,
 'type': 'pos',
 'user': '枫_先森'}
2020-05-10 10:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'LU过过过7'}
2020-05-10 10:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '永远有个遗憾落在了那个夏天。但还是很高兴能遇见江洋。',
 'essay_id': 0,
 'fav_nums': '15',
 'label': '上海堡垒',
 'score': 0.9937,
 'type': 'pos',
 'user': 'L兮儿7'}
2020-05-10 10:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-17',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '鹿宝宝超可爱的'}
2020-05-10 10:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '顶一楼！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.354,
 'type': 'neg',
 'user': 'W自信96247'}
2020-05-10 10:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '芦苇',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7298,
 'type': 'pos',
 'user': '这个天使太磨人'}
2020-05-10 10:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': ' 百度鹿晗吧，陪你闯天下💛',
 'essay_id': 0,
 'fav_nums': '12',
 'label': '上海堡垒',
 'score': 0.4727,
 'type': 'neg',
 'user': 'M唯鹿主义者M'}
2020-05-10 10:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '啊啊啊，好可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9515,
 'type': 'pos',
 'user': '萱姿鹿'}
2020-05-10 10:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '一部电影好与不好，全寄希望于一个人？每个角色都很重要，而且导演作为一部戏的中心，最关键的好吗，把责任一味地推到一位演员身上，很没担当诶',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.9999,
 'type': 'pos',
 'user': 'Carlyn_安安'}
2020-05-10 10:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': ' 天辽地宁，与鹿同行',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.1395,
 'type': 'neg',
 'user': '馨之晶莹'}
2020-05-10 10:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4386288000091686> (referer: None)
2020-05-10 10:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4445727071305724> (referer: None)
2020-05-10 10:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404473163924001> (referer: None)
2020-05-10 10:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4336330416371642> (referer: None)
2020-05-10 10:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404808850936271> (referer: None)
2020-05-10 10:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404496932865057> (referer: None)
2020-05-10 10:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4453795063054257> (referer: None)
2020-05-10 10:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '摩点没下线…别的家都开了',
 'essay_id': 0,
 'fav_nums': '9',
 'label': '上海堡垒',
 'score': 0.2575,
 'type': 'neg',
 'user': '老虎融化为黄油'}
2020-05-10 10:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '嗷！好可爱！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8673,
 'type': 'pos',
 'user': '鹿糖呐'}
2020-05-10 10:55:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '转',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4846,
 'type': 'neg',
 'user': 'L看清了_936'}
2020-05-10 10:55:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '天辽地宁，与鹿同行',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1395,
 'type': 'neg',
 'user': '醉橘夏'}
2020-05-10 10:55:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦了',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.82,
 'type': 'pos',
 'user': '咔哇咿娜比'}
2020-05-10 10:55:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-17',
 'content': '🉑🉑🉑',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': 'M夏令时M'}
2020-05-10 10:55:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '你在向往的生活里是怎么说的？',
 'essay_id': 0,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.9149,
 'type': 'pos',
 'user': '风花雪月_97691'}
2020-05-10 10:55:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4386288000091686", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:55:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 59655
2020-05-10 10:55:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 59655
2020-05-10 10:55:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:55:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 59655
2020-05-10 10:55:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 59655
2020-05-10 10:55:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '天辽地宁与鹿同行！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1395,
 'type': 'neg',
 'user': '許一卋安暖'}
2020-05-10 10:55:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4445727071305724", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:55:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 62134
2020-05-10 10:55:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 62134
2020-05-10 10:55:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4445727071305724>
{'add_time': '2019-12-4',
 'content': '他是唯一一个离世 却让我哭鼻子👃的艺人。以翔一路走好',
 'essay_id': 221,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9815,
 'type': 'pos',
 'user': 'Tina-张珂菡'}
2020-05-10 10:55:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402012919971507> (referer: None)
2020-05-10 10:55:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4336063729978447> (referer: None)
2020-05-10 10:55:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4187122292937189> (referer: None)
2020-05-10 10:55:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4383519922827650> (referer: None)
2020-05-10 10:55:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4336066754827248> (referer: None)
2020-05-10 10:55:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4187122258228984> (referer: None)
2020-05-10 10:55:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403690464963233> (referer: None)
2020-05-10 10:55:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404473163924001", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:55:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 52969
2020-05-10 10:55:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 52969
2020-05-10 10:55:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4404473163924001>
{'add_time': '2019-8-12',
 'content': '希望大家多多支持上海堡垒……独家手机合作伙伴——小米，别让小米亏得太惨了',
 'essay_id': 132,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.7776,
 'type': 'pos',
 'user': '我爱雷总的发布会'}
2020-05-10 10:55:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4336330416371642", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:55:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 47056
2020-05-10 10:55:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 47056
2020-05-10 10:55:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:55:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:40 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 47056
2020-05-10 10:55:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:40 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 47056
2020-05-10 10:55:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404808850936271", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:55:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 49089
2020-05-10 10:55:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 49089
2020-05-10 10:55:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4404808850936271>
{'add_time': '2019-8-13',
 'content': '大不了把那些片段放出来，我们粉丝自己剪啊啊啊啊',
 'essay_id': 206,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9883,
 'type': 'pos',
 'user': '日月草7772017'}
2020-05-10 10:55:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404496932865057", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:55:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 61226
2020-05-10 10:55:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 61226
2020-05-10 10:55:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4404496932865057>
{'add_time': '2019-8-12',
 'content': '哦豁我也在第一排',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.3266,
 'type': 'neg',
 'user': 'Kotkaaaa'}
2020-05-10 10:55:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4453795063054257", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:55:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 64406
2020-05-10 10:55:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:55:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:55:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 64406
2020-05-10 10:55:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4453795063054257>
{'add_time': '2019-12-26',
 'content': '可能亏损的那个表基本没什么意义，数据基本没参考价值。',
 'essay_id': 165,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.1661,
 'type': 'neg',
 'user': '山中宰相David'}
2020-05-10 10:56:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦啦',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.82,
 'type': 'pos',
 'user': '拾月限定心动'}
2020-05-10 10:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱！！！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6297,
 'type': 'pos',
 'user': '鹿阿霜Andy'}
2020-05-10 10:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '程秀清'}
2020-05-10 10:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '天辽地宁，与鹿同行',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1395,
 'type': 'neg',
 'user': '小鹿仙游420'}
2020-05-10 10:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4445727071305724>
{'add_time': '2019-12-11',
 'content': '果真是事事不如人意，难过的让人心颤…[淚]',
 'essay_id': 221,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8054,
 'type': 'pos',
 'user': '小花小花儿555'}
2020-05-10 10:56:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404725980452066> (referer: None)
2020-05-10 10:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4404473163924001>
{'add_time': '2019-8-12',
 'content': '你说的有点对呀',
 'essay_id': 132,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.3088,
 'type': 'neg',
 'user': '雷总给卢总一斤优质小米煮粥喝'}
2020-05-10 10:56:03 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 15 pages/min), scraped 76 items (at 60 items/min)
2020-05-10 10:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4404496932865057>
{'add_time': '2019-8-12',
 'content': '你有大合照吗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5057,
 'type': 'pos',
 'user': 'Ch_Loe1'}
2020-05-10 10:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4453795063054257>
{'add_time': '2019-12-26',
 'content': '吒儿好棒！',
 'essay_id': 165,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8631,
 'type': 'pos',
 'user': '仲夏之星骐天'}
2020-05-10 10:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '     想给你最好的 愿你得到最好的 在小贵分心里 你是最好的',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8382,
 'type': 'pos',
 'user': '鹿晗吧贵州分会'}
2020-05-10 10:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '我爱你',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7483,
 'type': 'pos',
 'user': '不想迷糊糊'}
2020-05-10 10:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-22',
 'content': '鹿晗：我有逼你们看吗？',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6092,
 'type': 'pos',
 'user': '松本人'}
2020-05-10 10:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '天辽地宁，与鹿同行',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1395,
 'type': 'neg',
 'user': '鹿·王者'}
2020-05-10 10:56:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402012919971507", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:56:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:09 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 94334
2020-05-10 10:56:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:09 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 94334
2020-05-10 10:56:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:12 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 131306
2020-05-10 10:56:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 167145
2020-05-10 10:56:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=14000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 167145
2020-05-10 10:56:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 167145
2020-05-10 10:56:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '鹿晗实事群'}
2020-05-10 10:56:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4336063729978447", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:56:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 84702
2020-05-10 10:56:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 84702
2020-05-10 10:56:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:21 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:23 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 84688
2020-05-10 10:56:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 84688
2020-05-10 10:56:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊期待江洋哥哥',
 'essay_id': 0,
 'fav_nums': '2264',
 'label': '上海堡垒',
 'score': 0.998,
 'type': 'pos',
 'user': '少爷姓鹿单字晗'}
2020-05-10 10:56:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4187122292937189", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:56:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:29 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 96775
2020-05-10 10:56:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:29 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 96775
2020-05-10 10:56:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:31 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 150696
2020-05-10 10:56:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:34 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 196760
2020-05-10 10:56:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=14000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:36 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 236016
2020-05-10 10:56:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=17500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 273270
2020-05-10 10:56:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=21000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:40 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 273256
2020-05-10 10:56:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:41 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 273256
2020-05-10 10:56:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '表白鹿晗',
 'essay_id': 152,
 'fav_nums': '2339',
 'label': '上海堡垒',
 'score': 0.3013,
 'type': 'neg',
 'user': '三年真的够了'}
2020-05-10 10:56:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4383519922827650", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:56:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 95221
2020-05-10 10:56:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 95221
2020-05-10 10:56:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 134316
2020-05-10 10:56:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 170892
2020-05-10 10:56:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=14000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 211861
2020-05-10 10:56:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=17500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 247157
2020-05-10 10:56:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=21000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:58 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 282042
2020-05-10 10:56:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:56:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=24500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:56:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:56:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:00 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 318748
2020-05-10 10:57:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=28000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:57:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:03 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 318734
2020-05-10 10:57:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:03 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 318734
2020-05-10 10:57:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '我总感觉鹿小晗不敢直视舒淇姐姐',
 'essay_id': 0,
 'fav_nums': 13000.0,
 'label': '上海堡垒',
 'score': 0.7047,
 'type': 'pos',
 'user': '星星住在月亮对岸'}
2020-05-10 10:57:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4336066754827248", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:57:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:31 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 92294
2020-05-10 10:57:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 92294
2020-05-10 10:57:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:57:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:34 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 132264
2020-05-10 10:57:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:57:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:36 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 166287
2020-05-10 10:57:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:36 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 166287
2020-05-10 10:57:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！新年快乐',
 'essay_id': 83,
 'fav_nums': '10',
 'label': '上海堡垒',
 'score': 0.6911,
 'type': 'pos',
 'user': '糖心鹿鹿_V'}
2020-05-10 10:57:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4187122258228984", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 72
2020-05-10 10:57:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 86810
2020-05-10 10:57:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 86810
2020-05-10 10:57:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=7000", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:57:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 134671
2020-05-10 10:57:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/execute {"script": "var q=document.documentElement.scrollTop=10500", "args": [], "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/execute HTTP/1.1" 200 72
2020-05-10 10:57:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 134657
2020-05-10 10:57:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/source {"sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "GET /session/e7f5f6d3603a2caed104f2b6543975b2/source HTTP/1.1" 200 134657
2020-05-10 10:57:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '我爱江洋[淚][淚][淚]',
 'essay_id': 106,
 'fav_nums': 13000.0,
 'label': '上海堡垒',
 'score': 0.6552,
 'type': 'pos',
 'user': '葫芦娃八条腿'}
2020-05-10 10:57:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403690464963233", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 10:57:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403690464963233> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 10:57:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4404496932865057>
{'add_time': '2019-8-12',
 'content': '离得这么近',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5893,
 'type': 'pos',
 'user': '只想一个人安静的躲在角落里'}
2020-05-10 10:57:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': ' 你是远方星球的引力，所以我潮汐不止！',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9826,
 'type': 'pos',
 'user': '鹿晗吧浙江分会'}
2020-05-10 10:57:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '朝鹿晗晓'}
2020-05-10 10:57:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-21',
 'content': '这是送分题我会 英语经常这么干',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.3195,
 'type': 'neg',
 'user': '我还要努力'}
2020-05-10 10:57:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '我一直在',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': 'M弹肖邦不忧桑M'}
2020-05-10 10:57:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '图四的可爱 加油 加油 加油＾０＾~',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.9998,
 'type': 'pos',
 'user': '柒花鹿草'}
2020-05-10 10:57:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '期待江洋*77777777777777777',
 'essay_id': 0,
 'fav_nums': '1847',
 'label': '上海堡垒',
 'score': 0.6831,
 'type': 'pos',
 'user': '杰2c1'}
2020-05-10 10:57:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待鹿晗',
 'essay_id': 152,
 'fav_nums': '1567',
 'label': '上海堡垒',
 'score': 0.6423,
 'type': 'pos',
 'user': '鹿鹿薇薇'}
2020-05-10 10:57:54 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 96 items (at 20 items/min)
2020-05-10 10:57:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '最后那张是慈善会的时候吗？',
 'essay_id': 0,
 'fav_nums': '4281',
 'label': '上海堡垒',
 'score': 0.7862,
 'type': 'pos',
 'user': '念鹿SL947'}
2020-05-10 10:57:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '养渽宝典'}
2020-05-10 10:57:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '鹿哥，杀青咯好好休息一下，期待热血街舞团！！',
 'essay_id': 106,
 'fav_nums': 12000.0,
 'label': '上海堡垒',
 'score': 0.601,
 'type': 'pos',
 'user': '读不通三千道藏'}
2020-05-10 10:57:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404725980452066", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:57:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 10:57:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:57:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404725980452066> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 10:57:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4404496932865057>
{'add_time': '2019-8-12',
 'content': '好好看😊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6032,
 'type': 'pos',
 'user': '一个纯纯纯无聊的人'}
2020-05-10 10:58:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '  陪你闯天下',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.577,
 'type': 'pos',
 'user': '鹿晗吧福建分会'}
2020-05-10 10:58:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '端木邨'}
2020-05-10 10:58:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '不远，没有我选的选项，我要选观众，没有观众哪来的票房？',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9998,
 'type': 'pos',
 'user': '青丝玉帛庸木'}
2020-05-10 10:58:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '天辽地宁，与鹿同行',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1395,
 'type': 'neg',
 'user': 'M迷鹿LH7M'}
2020-05-10 10:58:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4459665956422040> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403621129407520> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4465456234179986> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': ' 每一张都可爱',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.6874,
 'type': 'pos',
 'user': '古卷墨香闻鹿心'}
2020-05-10 10:58:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '鹿鹿',
 'essay_id': 0,
 'fav_nums': '1173',
 'label': '上海堡垒',
 'score': 0.4738,
 'type': 'neg',
 'user': 'sodaOoOoOo'}
2020-05-10 10:58:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待《上海堡垒》 期待江洋',
 'essay_id': 152,
 'fav_nums': '1462',
 'label': '上海堡垒',
 'score': 0.7641,
 'type': 'pos',
 'user': '鹿晗家的cat大人'}
2020-05-10 10:58:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '这张 帅气姐弟',
 'essay_id': 0,
 'fav_nums': '4153',
 'label': '上海堡垒',
 'score': 0.8342,
 'type': 'pos',
 'user': 'pink查克拉'}
2020-05-10 10:58:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！',
 'essay_id': 83,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8158,
 'type': 'pos',
 'user': '是喜欢鹿晗的珍妮'}
2020-05-10 10:58:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '谢谢你江洋，辛苦了鹿晗',
 'essay_id': 106,
 'fav_nums': 11000.0,
 'label': '上海堡垒',
 'score': 0.8416,
 'type': 'pos',
 'user': '鹿透社'}
2020-05-10 10:58:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '组织和实施的姐姐们辛苦了，这个夏天难以忘怀，还好有你们一鹿陪伴，加油',
 'essay_id': 0,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '兔兔-雪后初晴'}
2020-05-10 10:58:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '江洋，加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9112,
 'type': 'pos',
 'user': 'SMJlz'}
2020-05-10 10:58:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '缺一不可？你是在搞笑么？那这个问题有啥意义？',
 'essay_id': 0,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.7144,
 'type': 'pos',
 'user': '村野春光WQB'}
2020-05-10 10:58:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '遇见Lucky777'}
2020-05-10 10:58:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': 'SunFlower_鹿晗资源博'}
2020-05-10 10:58:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊啊啊堡宝',
 'essay_id': 0,
 'fav_nums': '1037',
 'label': '上海堡垒',
 'score': 0.9681,
 'type': 'pos',
 'user': '蜜糖冰美式'}
2020-05-10 10:58:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '呜哇！有一个帅哥哥',
 'essay_id': 152,
 'fav_nums': '1025',
 'label': '上海堡垒',
 'score': 0.9973,
 'type': 'pos',
 'user': '小玫瑰颂诗班'}
2020-05-10 10:58:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '帅哥美女真养眼',
 'essay_id': 0,
 'fav_nums': '3285',
 'label': '上海堡垒',
 'score': 0.9984,
 'type': 'pos',
 'user': '白日梦里看风景·'}
2020-05-10 10:58:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快樂',
 'essay_id': 83,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8162,
 'type': 'pos',
 'user': '黃小雅乖乖'}
2020-05-10 10:58:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '啊啊啊啊啊啊啊好的[淚][淚][淚][淚]',
 'essay_id': 106,
 'fav_nums': '6959',
 'label': '上海堡垒',
 'score': 0.9474,
 'type': 'pos',
 'user': '葫芦娃八条腿'}
2020-05-10 10:58:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '为什么文案不能精简点 直接jz+付钱的方式就行了 每次都不该 没看到你爱鹿晗的心',
 'essay_id': 0,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.5734,
 'type': 'pos',
 'user': 'zhongyue-forever'}
2020-05-10 10:58:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '希望像星星一样闪耀'}
2020-05-10 10:58:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '人间疾苦0835'}
2020-05-10 10:58:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '有盘锦场吗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7051,
 'type': 'pos',
 'user': 'blingbling-2021欧洲杯'}
2020-05-10 10:58:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '露点头发也太好看啦',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.7092,
 'type': 'pos',
 'user': '隔格不如'}
2020-05-10 10:58:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '等你啊等你！大堡贝',
 'essay_id': 0,
 'fav_nums': '872',
 'label': '上海堡垒',
 'score': 0.7501,
 'type': 'pos',
 'user': '泡泡小熊加湿器'}
2020-05-10 10:58:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待江洋！！！！！',
 'essay_id': 152,
 'fav_nums': '945',
 'label': '上海堡垒',
 'score': 0.2312,
 'type': 'neg',
 'user': 'Liyoune_'}
2020-05-10 10:58:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '0809看《上海堡垒》',
 'essay_id': 0,
 'fav_nums': '2406',
 'label': '上海堡垒',
 'score': 0.4652,
 'type': 'neg',
 'user': '白日梦里看风景·'}
2020-05-10 10:58:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': 'L遇W见H'}
2020-05-10 10:58:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '期待江洋',
 'essay_id': 106,
 'fav_nums': '6201',
 'label': '上海堡垒',
 'score': 0.7053,
 'type': 'pos',
 'user': '快乐糕崽'}
2020-05-10 10:58:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '大吧大吧，我个憨憨我转到上次的号里了，没事吧',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.2288,
 'type': 'neg',
 'user': '盒总不叫Andy'}
2020-05-10 10:58:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-17',
 'content': '超可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8288,
 'type': 'pos',
 'user': '鹿过的小仙男师父'}
2020-05-10 10:58:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-22',
 'content': '上海堡垒在网上连抢版都没有，这应该是对一部院线电影最大的侮辱。',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.6473,
 'type': 'pos',
 'user': '冰霜隐于世'}
2020-05-10 10:58:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '棒棒哒',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4738,
 'type': 'neg',
 'user': '蒹葭鹤人'}
2020-05-10 10:58:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4407346966722234> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '小可爱',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.8105,
 'type': 'pos',
 'user': '抱紧鹿狍儿'}
2020-05-10 10:58:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊啊啊啊啊小堡垒！！',
 'essay_id': 0,
 'fav_nums': '757',
 'label': '上海堡垒',
 'score': 0.9555,
 'type': 'pos',
 'user': '鹿遇普罗旺斯21'}
2020-05-10 10:58:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待江洋',
 'essay_id': 152,
 'fav_nums': '871',
 'label': '上海堡垒',
 'score': 0.7053,
 'type': 'pos',
 'user': '我从来不会生气'}
2020-05-10 10:58:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '期待0809鹿晗对舒淇姐姐爱而不得的表演！',
 'essay_id': 0,
 'fav_nums': '2142',
 'label': '上海堡垒',
 'score': 0.975,
 'type': 'pos',
 'user': 'susangreen777'}
2020-05-10 10:58:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！新年快乐',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6911,
 'type': 'pos',
 'user': 'L全能鹿辣辣7'}
2020-05-10 10:58:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '过分了！！！！！',
 'essay_id': 106,
 'fav_nums': '5846',
 'label': '上海堡垒',
 'score': 0.0417,
 'type': 'neg',
 'user': 'M莫哥M'}
2020-05-10 10:58:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '  ',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': 'M鹿MCatherine'}
2020-05-10 10:58:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '萌',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7778,
 'type': 'pos',
 'user': '高速鹿M傻狍子7777777'}
2020-05-10 10:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '选项里面居然没有让蔡徐坤去演！让流量明星上阵！这才是电影票房的保证！这个上海堡垒之所以没票房就是因为鹿晗现在没以前火了，过气了，知道不！',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.7111,
 'type': 'pos',
 'user': 'Rascal-91975'}
2020-05-10 10:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '幸运的我还中了奖，真好',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9798,
 'type': 'pos',
 'user': '七号鹿柴痴'}
2020-05-10 10:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': 'p4憨憨加油 p5憨憨惊讶 p9憨憨拆话筒',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9814,
 'type': 'pos',
 'user': '鹿笙鼓瑟'}
2020-05-10 10:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '期待鹿晗🙊🙊🙊🙊🙊🙊🙊🙊',
 'essay_id': 0,
 'fav_nums': '604',
 'label': '上海堡垒',
 'score': 0.6178,
 'type': 'pos',
 'user': '鹿帝御夫'}
2020-05-10 10:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '19年见了，江洋',
 'essay_id': 152,
 'fav_nums': '790',
 'label': '上海堡垒',
 'score': 0.3324,
 'type': 'neg',
 'user': 'M小泡芙M'}
2020-05-10 10:58:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '果然大家都爱看帅哥美女',
 'essay_id': 0,
 'fav_nums': '1755',
 'label': '上海堡垒',
 'score': 0.6989,
 'type': 'pos',
 'user': '白日梦里看风景·'}
2020-05-10 10:58:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '寻鹿启示7'}
2020-05-10 10:58:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '鹿哥加油',
 'essay_id': 106,
 'fav_nums': '4868',
 'label': '上海堡垒',
 'score': 0.8953,
 'type': 'pos',
 'user': '迷鹿oba'}
2020-05-10 10:58:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '陪你闯天下',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.577,
 'type': 'pos',
 'user': '呦呦甜盐果'}
2020-05-10 10:58:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '黄色郁金香的痛……',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7212,
 'type': 'pos',
 'user': '风之诺言阳光'}
2020-05-10 10:58:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '这部电影成功关闭了中国科幻片的序幕。',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.9723,
 'type': 'pos',
 'user': 'Revolver-Y'}
2020-05-10 10:58:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '我的大堡贝',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7501,
 'type': 'pos',
 'user': '做哥哥的冰美式'}
2020-05-10 10:58:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4470033083931076> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '哇⊙∀⊙！昨天没见这个',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.3114,
 'type': 'neg',
 'user': '请问你是膀大腰圆的芦苇姐姐吗'}
2020-05-10 10:58:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊我靠',
 'essay_id': 0,
 'fav_nums': '454',
 'label': '上海堡垒',
 'score': 0.9997,
 'type': 'pos',
 'user': '呦呦鹿梦'}
2020-05-10 10:58:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '江洋哥哥',
 'essay_id': 152,
 'fav_nums': '581',
 'label': '上海堡垒',
 'score': 0.9719,
 'type': 'pos',
 'user': 'M-小太阳-M'}
2020-05-10 10:58:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '相比较下来，第三张鹿鹿真的好奶哦，像个糯米团子',
 'essay_id': 0,
 'fav_nums': '1677',
 'label': '上海堡垒',
 'score': 0.5671,
 'type': 'pos',
 'user': '半截眼镜腿儿'}
2020-05-10 10:58:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6391,
 'type': 'pos',
 'user': '橘味小懵儿'}
2020-05-10 10:58:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '恭喜杀青',
 'essay_id': 106,
 'fav_nums': '3991',
 'label': '上海堡垒',
 'score': 0.7298,
 'type': 'pos',
 'user': '鹿晗快别撩我了'}
2020-05-10 10:58:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '百度鹿晗吧，陪你闯天下。',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.4989,
 'type': 'neg',
 'user': 'Andy-汀瓜'}
2020-05-10 10:58:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '咧咧咧六六六',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': 'susangreen777'}
2020-05-10 10:58:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '怎么说呢，流量明星的演技怎么心里没点普吗？自己想靠流量明星保本，结果亏了，自己不应该反思吗？而且除了这个问题，这本电影本身也是有问题的',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9828,
 'type': 'pos',
 'user': '刚好二十七八岁'}
2020-05-10 10:58:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '我被挡住了，我第二排的',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1435,
 'type': 'neg',
 'user': '炎晓璐'}
2020-05-10 10:58:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4468312710429328> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-6',
 'content': '最后一张感觉老鹿想拆话筒😂 😂 😂',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6738,
 'type': 'pos',
 'user': '狍子鹿晗LH7'}
2020-05-10 10:58:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊啊是我们大堡垒～',
 'essay_id': 0,
 'fav_nums': '432',
 'label': '上海堡垒',
 'score': 0.9574,
 'type': 'pos',
 'user': '春桃仙子鹿'}
2020-05-10 10:58:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '我江洋哥哥',
 'essay_id': 152,
 'fav_nums': '513',
 'label': '上海堡垒',
 'score': 0.9719,
 'type': 'pos',
 'user': 'M刘Emily'}
2020-05-10 10:58:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '可爱鹿5晗本鹿',
 'essay_id': 0,
 'fav_nums': '1096',
 'label': '上海堡垒',
 'score': 0.7025,
 'type': 'pos',
 'user': '意中人是阿鹿'}
2020-05-10 10:58:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '肋骨上的海棠'}
2020-05-10 10:58:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '啊啊啊，江洋哥哥',
 'essay_id': 106,
 'fav_nums': '3493',
 'label': '上海堡垒',
 'score': 0.9894,
 'type': 'pos',
 'user': '甄小娅'}
2020-05-10 10:58:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '陪鹿晗闯天下💛💛',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.4989,
 'type': 'neg',
 'user': 'iluoox'}
2020-05-10 10:58:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '江江宝贝',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7511,
 'type': 'pos',
 'user': '似晨光熹微'}
2020-05-10 10:58:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '编剧编得烂，导演导得不好，关演员什么事！我女儿和我妹去看了，说是故事情节太烂了好吧！',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.162,
 'type': 'neg',
 'user': '依然为你守着约'}
2020-05-10 10:58:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '好棒！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.875,
 'type': 'pos',
 'user': '飞鸣99103'}
2020-05-10 10:58:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4468014626157609> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4465456234179986> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403621129407520> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4459665956422040> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-8',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '语菲儿003'}
2020-05-10 10:58:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊 我的天呐！！大堡竟然更博了',
 'essay_id': 0,
 'fav_nums': '396',
 'label': '上海堡垒',
 'score': 0.9998,
 'type': 'pos',
 'user': '北京鹿纯爷们儿'}
2020-05-10 10:58:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待出色的你！',
 'essay_id': 152,
 'fav_nums': '445',
 'label': '上海堡垒',
 'score': 0.9128,
 'type': 'pos',
 'user': 'M玉佳'}
2020-05-10 10:58:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '舒淇一直这么可爱，嗲嗲的却不招人烦',
 'essay_id': 0,
 'fav_nums': '795',
 'label': '上海堡垒',
 'score': 0.1681,
 'type': 'neg',
 'user': '幸福的奶茶工锵锵'}
2020-05-10 10:58:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6391,
 'type': 'pos',
 'user': '酸奶很辣a'}
2020-05-10 10:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '最帅的鹿哥',
 'essay_id': 106,
 'fav_nums': '3089',
 'label': '上海堡垒',
 'score': 0.6429,
 'type': 'pos',
 'user': '孟子坤··'}
2020-05-10 10:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '百度鹿晗吧，陪你闯天下',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.4989,
 'type': 'neg',
 'user': '鹿少年追梦部落'}
2020-05-10 10:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '很可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.887,
 'type': 'pos',
 'user': '熊一鹿伴晗'}
2020-05-10 10:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '多余的选项',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6393,
 'type': 'pos',
 'user': '我真的不曾知道名字可以这么长'}
2020-05-10 10:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '猫十七酱'}
2020-05-10 10:58:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4465755779581713> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '加油＾０＾~',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8953,
 'type': 'pos',
 'user': 'M鹿M宝小晗i'}
2020-05-10 10:58:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '我的江洋哥哥啊啊啊啊啊 我等您今年来救我🙉🙉🙉',
 'essay_id': 0,
 'fav_nums': '328',
 'label': '上海堡垒',
 'score': 0.9982,
 'type': 'pos',
 'user': 'KINI吉籽甜憨'}
2020-05-10 10:58:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待',
 'essay_id': 152,
 'fav_nums': '436',
 'label': '上海堡垒',
 'score': 0.689,
 'type': 'pos',
 'user': '金金金鹿'}
2020-05-10 10:58:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '第三张是哪的？',
 'essay_id': 0,
 'fav_nums': '711',
 'label': '上海堡垒',
 'score': 0.2094,
 'type': 'neg',
 'user': '迈过星河迎接鹿晗'}
2020-05-10 10:58:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '春桃仙子鹿'}
2020-05-10 10:58:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '2019见',
 'essay_id': 106,
 'fav_nums': '3010',
 'label': '上海堡垒',
 'score': 0.361,
 'type': 'neg',
 'user': 'PerAsperaAdAstra·'}
2020-05-10 10:58:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '我们一起陪你闯天下',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.577,
 'type': 'pos',
 'user': '一曲花间醉'}
2020-05-10 10:58:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱的江洋哥哥啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9956,
 'type': 'pos',
 'user': '国教学院院长7'}
2020-05-10 10:58:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-26',
 'content': '剧情的问题',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6316,
 'type': 'pos',
 'user': '海de另一边丫'}
2020-05-10 10:58:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '棒棒哒！加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8851,
 'type': 'pos',
 'user': '今生最美的相遇LUHAN'}
2020-05-10 10:58:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': 'p4是什么绝世可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9473,
 'type': 'pos',
 'user': '吧唧一口鹿5晗'}
2020-05-10 10:58:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '期待江洋哥哥',
 'essay_id': 0,
 'fav_nums': '285',
 'label': '上海堡垒',
 'score': 0.9857,
 'type': 'pos',
 'user': 'pink查克拉'}
2020-05-10 10:58:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待江洋，期待《上海堡垒》',
 'essay_id': 152,
 'fav_nums': '380',
 'label': '上海堡垒',
 'score': 0.7641,
 'type': 'pos',
 'user': '鹿晗借我点钱'}
2020-05-10 10:58:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '好可爱一小男孩！',
 'essay_id': 0,
 'fav_nums': '668',
 'label': '上海堡垒',
 'score': 0.9679,
 'type': 'pos',
 'user': '鹿屿Andy'}
2020-05-10 10:58:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '甜鹿鹿_7'}
2020-05-10 10:58:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '哇，江洋哥哥',
 'essay_id': 106,
 'fav_nums': '2859',
 'label': '上海堡垒',
 'score': 0.9719,
 'type': 'pos',
 'user': '古卷墨香闻鹿心'}
2020-05-10 10:58:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': ' 百度鹿晗吧，陪你闯天下',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.4989,
 'type': 'neg',
 'user': '喜欢七号的少年'}
2020-05-10 10:58:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '可怜的江洋',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4259,
 'type': 'neg',
 'user': '茉莉遇寒'}
2020-05-10 10:58:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-22',
 'content': '下',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5042,
 'type': 'pos',
 'user': '毕儒苟'}
2020-05-10 10:58:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '你们好棒呀',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.875,
 'type': 'pos',
 'user': '我是七你是鹿'}
2020-05-10 10:58:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4457158055895490> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '哎呀，这是新的鹿鹿',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5967,
 'type': 'pos',
 'user': 'lilian6677'}
2020-05-10 10:58:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊啊啊啊，江洋！！！',
 'essay_id': 0,
 'fav_nums': '255',
 'label': '上海堡垒',
 'score': 0.9373,
 'type': 'pos',
 'user': '糖心鹿鹿_V'}
2020-05-10 10:58:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 期待鹿晗～',
 'essay_id': 152,
 'fav_nums': '332',
 'label': '上海堡垒',
 'score': 0.667,
 'type': 'pos',
 'user': '如鹿切慕溪水reed'}
2020-05-10 10:58:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '我好喜欢他俩的互动啊！！！ 舒淇好可爱！！ 感觉很好玩！！ 整个剧组都很可爱！我猜两个人私底下聊天应该也挺有意思的',
 'essay_id': 0,
 'fav_nums': '558',
 'label': '上海堡垒',
 'score': 0.9999,
 'type': 'pos',
 'user': '今天的晚安呢'}
2020-05-10 10:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': 'lovedeeryo'}
2020-05-10 10:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊我爱你！！！！！！啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊',
 'essay_id': 106,
 'fav_nums': '2091',
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '专业是做白日梦qwq'}
2020-05-10 10:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦了',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.82,
 'type': 'pos',
 'user': 'HANXLU7'}
2020-05-10 10:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱的江洋啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.887,
 'type': 'pos',
 'user': '苏子叶_'}
2020-05-10 10:58:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-21',
 'content': '服了 我一个路人都看不下去了 这又开始骂蔡徐坤了？之前喷因为鹿晗演不看 播完了又喷要不是鹿晗就不去看 '
            '现在又喷蔡徐坤粉丝多？你要不先去喷喷废青？不想喷废青就把你嘴闭上',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.0002,
 'type': 'neg',
 'user': '失眠开始于每天和你说晚安'}
2020-05-10 10:58:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '哇偶',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5606,
 'type': 'pos',
 'user': '玖柒壹零'}
2020-05-10 10:58:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8089,
 'type': 'pos',
 'user': '1314不负好时光'}
2020-05-10 10:58:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊我的大堡贝终于有消息了',
 'essay_id': 0,
 'fav_nums': '238',
 'label': '上海堡垒',
 'score': 0.9223,
 'type': 'pos',
 'user': '小鹿小鹿你是最棒的'}
2020-05-10 10:58:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '表白鹿晗哥哥！！期待江洋',
 'essay_id': 152,
 'fav_nums': '296',
 'label': '上海堡垒',
 'score': 0.9146,
 'type': 'pos',
 'user': '糖山芒海'}
2020-05-10 10:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '超级可爱',
 'essay_id': 0,
 'fav_nums': '465',
 'label': '上海堡垒',
 'score': 0.7544,
 'type': 'pos',
 'user': 'L留鹿L'}
2020-05-10 10:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐！！期待堡垒，期待江洋哥哥',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9907,
 'type': 'pos',
 'user': '穿裤衩的噜噜'}
2020-05-10 10:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '上海见圣诞快乐！',
 'essay_id': 106,
 'fav_nums': '1965',
 'label': '上海堡垒',
 'score': 0.9662,
 'type': 'pos',
 'user': '陌沫yn'}
2020-05-10 10:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '百度鹿晗吧，陪你闯天下。',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.4989,
 'type': 'neg',
 'user': '专属彼得潘'}
2020-05-10 10:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '我来了，小江',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4903,
 'type': 'neg',
 'user': '星星住在月亮对岸'}
2020-05-10 10:58:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-21',
 'content': '剧本简直、看了预告就感觉像看过这个电影一样、总感觉和哪一步很像',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9891,
 'type': 'pos',
 'user': '初妍小星星'}
2020-05-10 10:58:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '脆弱的静语333'}
2020-05-10 10:58:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4455546046332498> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '好可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '鹿憨憨和鹿哥'}
2020-05-10 10:58:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '哇啊啊啊啊啊啊啊期待江洋哥哥！！！！！',
 'essay_id': 0,
 'fav_nums': '207',
 'label': '上海堡垒',
 'score': 0.9942,
 'type': 'pos',
 'user': '月明鹿星稀'}
2020-05-10 10:58:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '恭喜杀青 去休假吧 哈哈哈哈哈哈',
 'essay_id': 152,
 'fav_nums': '242',
 'label': '上海堡垒',
 'score': 0.9982,
 'type': 'pos',
 'user': '梨涡球球儿'}
2020-05-10 10:58:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '一直都这么可爱',
 'essay_id': 0,
 'fav_nums': '345',
 'label': '上海堡垒',
 'score': 0.824,
 'type': 'pos',
 'user': '背对背拥抱的Andy'}
2020-05-10 10:58:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '末鹿安然lm'}
2020-05-10 10:58:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '期待江洋',
 'essay_id': 106,
 'fav_nums': '1925',
 'label': '上海堡垒',
 'score': 0.7053,
 'type': 'pos',
 'user': 'lululululululuhan_'}
2020-05-10 10:58:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '2019遇见江洋，虽有遗憾仍感恩可以窥探到27岁那年他的模样！期待下一次相遇！',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9997,
 'type': 'pos',
 'user': 'Real-melv'}
2020-05-10 10:58:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '莫名有一种失落感   好像回到上周的今天',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9912,
 'type': 'pos',
 'user': '是鹿哥的橘子女孩'}
2020-05-10 10:58:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-21',
 'content': '剧情看不懂，所以没人看',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4637,
 'type': 'neg',
 'user': 'D-liu努力'}
2020-05-10 10:58:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '假装有我的亚子',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8021,
 'type': 'pos',
 'user': '比昨天更酷的橙子'}
2020-05-10 10:58:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4407346966722234> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '小柠檬！！！！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8978,
 'type': 'pos',
 'user': '似鸟投鹿林'}
2020-05-10 10:58:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊江洋哥哥！！！！',
 'essay_id': 0,
 'fav_nums': '185',
 'label': '上海堡垒',
 'score': 0.9854,
 'type': 'pos',
 'user': '李壮实的屁帘'}
2020-05-10 10:58:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '恭喜杀青',
 'essay_id': 152,
 'fav_nums': '246',
 'label': '上海堡垒',
 'score': 0.7298,
 'type': 'pos',
 'user': '锦鲤小仙女本仙'}
2020-05-10 10:58:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '好可爱一小朋友',
 'essay_id': 0,
 'fav_nums': '311',
 'label': '上海堡垒',
 'score': 0.9391,
 'type': 'pos',
 'user': '他叫鹿不羁'}
2020-05-10 10:58:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '7号冰芋圆_'}
2020-05-10 10:58:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '期待上海堡垒',
 'essay_id': 106,
 'fav_nums': '1772',
 'label': '上海堡垒',
 'score': 0.6004,
 'type': 'pos',
 'user': '微白city7'}
2020-05-10 10:58:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦了',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.82,
 'type': 'pos',
 'user': '请问你是膀大腰圆的芦苇姐姐吗'}
2020-05-10 10:58:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '小可爱江洋',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8221,
 'type': 'pos',
 'user': 'Demon凉生'}
2020-05-10 10:58:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-21',
 'content': '不是鹿晗自己说的“向我开炮”吗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1977,
 'type': 'neg',
 'user': 'GaoMJn'}
2020-05-10 10:58:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '超棒',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9,
 'type': 'pos',
 'user': '溫朵朵'}
2020-05-10 10:58:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4470033083931076> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404054458995779> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404477555352408> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4452214770251759> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '鹿鹿快点拍完出来玩吧',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7925,
 'type': 'pos',
 'user': '丧气指南_'}
2020-05-10 10:58:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '等大堡垒，等江洋，除夕快乐',
 'essay_id': 0,
 'fav_nums': '165',
 'label': '上海堡垒',
 'score': 0.9435,
 'type': 'pos',
 'user': '鱼雨语玉羽'}
2020-05-10 10:58:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '恭喜杀青！希望早点看到江洋',
 'essay_id': 152,
 'fav_nums': '221',
 'label': '上海堡垒',
 'score': 0.6993,
 'type': 'pos',
 'user': '一只路人糖'}
2020-05-10 10:58:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '谁还敢说没有cp感的！！！！',
 'essay_id': 0,
 'fav_nums': '291',
 'label': '上海堡垒',
 'score': 0.1586,
 'type': 'neg',
 'user': 'Ad-Astra苦旅'}
2020-05-10 10:58:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '  新年快乐！期待堡垒！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8114,
 'type': 'pos',
 'user': '喜帖鹿'}
2020-05-10 10:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊',
 'essay_id': 106,
 'fav_nums': '1434',
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '喵叽喵叽mm'}
2020-05-10 10:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '你是远方星球的引力，所以我潮夕不止',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9978,
 'type': 'pos',
 'user': 'Starlight·鹿H'}
2020-05-10 10:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '小江司令',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4641,
 'type': 'neg',
 'user': '长生入我相思局'}
2020-05-10 10:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '⊙∀⊙！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '池池池321'}
2020-05-10 10:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '棒棒的！[加油][加油][加油]',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '蓝色妖姬7771234'}
2020-05-10 10:58:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4468312710429328> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': ' 我的可爱宝贝呀',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9399,
 'type': 'pos',
 'user': '九零的鹿'}
2020-05-10 10:58:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '江洋：呵 早准备好了 尽管来吧',
 'essay_id': 0,
 'fav_nums': '148',
 'label': '上海堡垒',
 'score': 0.6699,
 'type': 'pos',
 'user': '喜欢的人叫鹿晗'}
2020-05-10 10:58:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '图二 真实的尖叫',
 'essay_id': 152,
 'fav_nums': '184',
 'label': '上海堡垒',
 'score': 0.7171,
 'type': 'pos',
 'user': '茉莉子熙'}
2020-05-10 10:58:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '上海堡垒电影票我买了，就等上映啦',
 'essay_id': 0,
 'fav_nums': '206',
 'label': '上海堡垒',
 'score': 0.4007,
 'type': 'neg',
 'user': '追梦少女林诗诗'}
2020-05-10 10:58:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！⚡ ⚡ ⚡',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7636,
 'type': 'pos',
 'user': '我家住在珠穆朗玛峰777'}
2020-05-10 10:58:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '江洋好帅啊啊啊啊啊',
 'essay_id': 106,
 'fav_nums': '1411',
 'label': '上海堡垒',
 'score': 0.8874,
 'type': 'pos',
 'user': 'TaurusAries4ever'}
2020-05-10 10:58:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦了',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.82,
 'type': 'pos',
 'user': 'Starlight·鹿H'}
2020-05-10 10:58:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '阿鹿的小居居'}
2020-05-10 10:58:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '一只糯糯呀'}
2020-05-10 10:58:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '转发微博',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6439,
 'type': 'pos',
 'user': '爱心妈妈2018'}
2020-05-10 10:58:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可可爱爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9189,
 'type': 'pos',
 'user': '呆萌鹿晗的七号房Orz'}
2020-05-10 10:58:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊啊超级期待啊 快上映！！！期待江洋！！！',
 'essay_id': 0,
 'fav_nums': '137',
 'label': '上海堡垒',
 'score': 0.8846,
 'type': 'pos',
 'user': '勋味憨鹿'}
2020-05-10 10:58:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '为江洋哥哥打call，辛苦了，恭喜杀青',
 'essay_id': 152,
 'fav_nums': '151',
 'label': '上海堡垒',
 'score': 0.9968,
 'type': 'pos',
 'user': '鹿芦晗晗憨憨'}
2020-05-10 10:58:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '面对漂亮姐姐还是会害羞',
 'essay_id': 0,
 'fav_nums': '265',
 'label': '上海堡垒',
 'score': 0.9947,
 'type': 'pos',
 'user': '鹿与卿言'}
2020-05-10 10:58:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '鹿鈺恣意_'}
2020-05-10 10:58:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '江洋哥哥',
 'essay_id': 106,
 'fav_nums': '1321',
 'label': '上海堡垒',
 'score': 0.9719,
 'type': 'pos',
 'user': 'sweetyu柚'}
2020-05-10 10:58:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '一起加油啊',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9048,
 'type': 'pos',
 'user': '北京鹿纯爷们儿'}
2020-05-10 10:58:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好看',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7112,
 'type': 'pos',
 'user': '芒果味的知世酱'}
2020-05-10 10:58:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '那只邪恶的猫'}
2020-05-10 10:58:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '重度拖延症候群'}
2020-05-10 10:58:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404092698693640> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '则祎'}
2020-05-10 10:58:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336063729978447>
{'add_time': '2019-2-4',
 'content': '啊啊啊啊啊啊啊啊啊我的江洋啊啊啊啊啊啊',
 'essay_id': 0,
 'fav_nums': '122',
 'label': '上海堡垒',
 'score': 0.9992,
 'type': 'pos',
 'user': '杰2c1'}
2020-05-10 10:58:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 恭喜杀青',
 'essay_id': 152,
 'fav_nums': '121',
 'label': '上海堡垒',
 'score': 0.7298,
 'type': 'pos',
 'user': 'Shirley敏啵'}
2020-05-10 10:58:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '哇哇哇哇，太帅啦，羡慕去现场的宝宝',
 'essay_id': 0,
 'fav_nums': '186',
 'label': '上海堡垒',
 'score': 0.9623,
 'type': 'pos',
 'user': 'dear鈺珺'}
2020-05-10 10:58:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐，猪年大吉',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2446,
 'type': 'neg',
 'user': 'MYCOCO酱'}
2020-05-10 10:58:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '#鹿晗# 哇！！！！我不知道说啥了！！！',
 'essay_id': 106,
 'fav_nums': '1084',
 'label': '上海堡垒',
 'score': 0.0015,
 'type': 'neg',
 'user': '宝宝鱼LJ'}
2020-05-10 10:58:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦啦！我们一鹿同行！',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.4507,
 'type': 'neg',
 'user': '奋斗的幸福LH7'}
2020-05-10 10:58:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '江洋好可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.887,
 'type': 'pos',
 'user': '一曲花间醉'}
2020-05-10 10:58:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '哈哈',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '局外人_yuan'}
2020-05-10 10:58:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'L看看就好L'}
2020-05-10 10:58:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '图片拍的不错！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8655,
 'type': 'pos',
 'user': '鲈颖MEi'}
2020-05-10 10:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '恭喜杀青，各位都辛苦了，期待鹿晗，我们2019见吧❤️',
 'essay_id': 152,
 'fav_nums': '102',
 'label': '上海堡垒',
 'score': 0.9006,
 'type': 'pos',
 'user': '奶味小噜'}
2020-05-10 10:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '热搜来啦',
 'essay_id': 0,
 'fav_nums': '112',
 'label': '上海堡垒',
 'score': 0.2107,
 'type': 'neg',
 'user': '肆月贰十'}
2020-05-10 10:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7056,
 'type': 'pos',
 'user': '无知无觉出世'}
2020-05-10 10:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '鹿哥 ',
 'essay_id': 106,
 'fav_nums': '1076',
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '快乐糕崽'}
2020-05-10 10:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': ' lh 演员鹿晗，我们后会有期',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.8969,
 'type': 'pos',
 'user': '芋泥可可星球'}
2020-05-10 10:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '这图喜欢',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7736,
 'type': 'pos',
 'user': 'ID双月'}
2020-05-10 10:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '怪林俊杰谁叫他唱了江南。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9271,
 'type': 'pos',
 'user': 'DASKLIS'}
2020-05-10 10:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '追风筝的迷鹿'}
2020-05-10 10:58:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4425100163674276> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:43 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4465456234179986> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4465755779581713> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:43 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4403621129407520> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4468014626157609> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '收图收图',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1101,
 'type': 'neg',
 'user': '一曲花间醉'}
2020-05-10 10:58:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '很酷很酷的江洋哥哥',
 'essay_id': 152,
 'fav_nums': '91',
 'label': '上海堡垒',
 'score': 0.9977,
 'type': 'pos',
 'user': '南栀静雅'}
2020-05-10 10:58:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '「上海电影节 上海堡垒剧组红毯」',
 'essay_id': 0,
 'fav_nums': '107',
 'label': '上海堡垒',
 'score': 0.5111,
 'type': 'pos',
 'user': '鹿·Andy棒棒·仙鹅'}
2020-05-10 10:58:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐，辛苦了',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9077,
 'type': 'pos',
 'user': '鹿先生的鹿晓七'}
2020-05-10 10:58:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '啊啊啊鹿晗 ',
 'essay_id': 106,
 'fav_nums': '972',
 'label': '上海堡垒',
 'score': 0.7086,
 'type': 'pos',
 'user': '高岭之小葵花'}
2020-05-10 10:58:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '风大雨大陪你闯天下！',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '鹿过无痕'}
2020-05-10 10:58:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '江洋加油啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9112,
 'type': 'pos',
 'user': '伦伦一鹿相伴'}
2020-05-10 10:58:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '这么好的作品，我认为上面所说的东西都缺一不可，但是最重要的东西还是演员们精妙的演技。这才是整部电影的灵魂！没有它，还叫什么烂片？',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9998,
 'type': 'pos',
 'user': '淡风82699'}
2020-05-10 10:58:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '沈阳能包个imax场么？直到现在都没有看到上海堡垒imax场是我最大的遗憾！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7337,
 'type': 'pos',
 'user': '盒子精的迷妹'}
2020-05-10 10:58:45 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4459665956422040> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4465456234179986>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4403621129407520>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '神图',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6914,
 'type': 'pos',
 'user': '兔小九喜欢鹿小七_'}
2020-05-10 10:58:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 表白少爷',
 'essay_id': 152,
 'fav_nums': '86',
 'label': '上海堡垒',
 'score': 0.6831,
 'type': 'pos',
 'user': '璃之簌簌'}
2020-05-10 10:58:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': ' 哈哈哈两个人都好可爱啊',
 'essay_id': 0,
 'fav_nums': '95',
 'label': '上海堡垒',
 'score': 0.9768,
 'type': 'pos',
 'user': 'MIsSJulyyy'}
2020-05-10 10:58:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐！都辛苦啦！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9158,
 'type': 'pos',
 'user': 'L游L鹿H'}
2020-05-10 10:58:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '2019年见 江洋',
 'essay_id': 106,
 'fav_nums': '949',
 'label': '上海堡垒',
 'score': 0.4932,
 'type': 'neg',
 'user': '迷鹿oba'}
2020-05-10 10:58:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦啦',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.82,
 'type': 'pos',
 'user': 'Mr鹿LH7sir'}
2020-05-10 10:58:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '   //',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2,
 'type': 'neg',
 'user': '鹿梦璃1994'}
2020-05-10 10:58:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '不站队，但觉得部分媒体断章取义，乱起标题，乱带节奏。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7029,
 'type': 'pos',
 'user': '一条名字各种被占用'}
2020-05-10 10:58:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '棒棒哒',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4738,
 'type': 'neg',
 'user': '曼听花园'}
2020-05-10 10:58:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4417610500627067> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 10:58:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4459665956422040>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可可爱爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9189,
 'type': 'pos',
 'user': '马上就要收获幸福的Demi'}
2020-05-10 10:58:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '恭喜上海堡垒杀青！辛苦啦！期待',
 'essay_id': 152,
 'fav_nums': '72',
 'label': '上海堡垒',
 'score': 0.9374,
 'type': 'pos',
 'user': '你是远方星球的引力·'}
2020-05-10 10:58:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': ' 都好可爱，真的是赏心悦目',
 'essay_id': 0,
 'fav_nums': '85',
 'label': '上海堡垒',
 'score': 0.9879,
 'type': 'pos',
 'user': 'o0Onlyone'}
2020-05-10 10:58:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '为了找路迷了鹿'}
2020-05-10 10:58:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '期待2019上海堡垒，期待江洋！',
 'essay_id': 106,
 'fav_nums': '838',
 'label': '上海堡垒',
 'score': 0.7446,
 'type': 'pos',
 'user': 'Keplerslaw_Starry'}
2020-05-10 10:58:47 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 316 items (at 220 items/min)
2020-05-10 10:58:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '加油，小芦们都在的',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9044,
 'type': 'pos',
 'user': '楠楠LuHan'}
2020-05-10 10:58:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '   好可爱的小江江！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8436,
 'type': 'pos',
 'user': '鹿梦璃1994'}
2020-05-10 10:58:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '上海堡垒我初中时看过，故事真的很流畅，本来真的很个很好的剧本的啊，可惜了。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9978,
 'type': 'pos',
 'user': '唔知叫咩吼'}
2020-05-10 10:58:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '一鹿同行',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1667,
 'type': 'neg',
 'user': '轻舞飞扬691020'}
2020-05-10 10:58:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '好可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '做个董美娃'}
2020-05-10 10:58:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待江洋！！辛苦了',
 'essay_id': 152,
 'fav_nums': '64',
 'label': '上海堡垒',
 'score': 0.797,
 'type': 'pos',
 'user': 'crushoonyou'}
2020-05-10 10:58:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': '80',
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '沫熙梓啊'}
2020-05-10 10:58:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '一定去看',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5748,
 'type': 'pos',
 'user': '归零的爱意'}
2020-05-10 10:58:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '期待江洋',
 'essay_id': 106,
 'fav_nums': '776',
 'label': '上海堡垒',
 'score': 0.7053,
 'type': 'pos',
 'user': '翎凌ling'}
2020-05-10 10:58:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '还闯天下呢，这个样子马上世界末日就来了',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9884,
 'type': 'pos',
 'user': 'Andy-LH7'}
2020-05-10 10:58:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '鹿梦璃1994'}
2020-05-10 10:58:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '哪一个完蛋都完蛋',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4774,
 'type': 'neg',
 'user': '倔强的涛儿'}
2020-05-10 10:58:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '加油加油加油我们芦苇真棒',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9993,
 'type': 'pos',
 'user': '鹿过阳光就灿烂'}
2020-05-10 10:58:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '好甜',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8512,
 'type': 'pos',
 'user': '伊雪衣'}
2020-05-10 10:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 超级期待啊啊啊',
 'essay_id': 152,
 'fav_nums': '58',
 'label': '上海堡垒',
 'score': 0.8128,
 'type': 'pos',
 'user': 'just狍'}
2020-05-10 10:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '一直都是可爱的小朋友',
 'essay_id': 0,
 'fav_nums': '74',
 'label': '上海堡垒',
 'score': 0.9086,
 'type': 'pos',
 'user': '傲娇爱笑的万万酱'}
2020-05-10 10:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': 'M麋鹿M_777'}
2020-05-10 10:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '哇，请开启舔屏模式',
 'essay_id': 106,
 'fav_nums': '719',
 'label': '上海堡垒',
 'score': 0.0457,
 'type': 'neg',
 'user': '麻辣影剧'}
2020-05-10 10:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦了，粉丝们。',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9111,
 'type': 'pos',
 'user': '大大小丸孑'}
2020-05-10 10:58:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-17',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '壹里星辰'}
2020-05-10 10:58:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '剧组所有人员的努力',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6045,
 'type': 'pos',
 'user': '牧羊的斑马'}
2020-05-10 10:58:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '辛苦了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.82,
 'type': 'pos',
 'user': '心上人是小鹿7'}
2020-05-10 10:58:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4457158055895490> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '余生亦有鹿'}
2020-05-10 10:58:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '哇！高高好帅！！',
 'essay_id': 152,
 'fav_nums': '68',
 'label': '上海堡垒',
 'score': 0.2647,
 'type': 'neg',
 'user': '听雨落凡尘'}
2020-05-10 10:58:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '我以为鹿晗背了个包，以为衣服上是书包带',
 'essay_id': 0,
 'fav_nums': '72',
 'label': '上海堡垒',
 'score': 0.7744,
 'type': 'pos',
 'user': '草芒mangoks'}
2020-05-10 10:58:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8158,
 'type': 'pos',
 'user': '给鹿晗wink'}
2020-05-10 10:58:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '我的江洋哥哥，2019影院见',
 'essay_id': 106,
 'fav_nums': '613',
 'label': '上海堡垒',
 'score': 0.9694,
 'type': 'pos',
 'user': '络深深'}
2020-05-10 10:58:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '陪他一起闯天下！',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.577,
 'type': 'pos',
 'user': '霓虹倒影'}
2020-05-10 10:58:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-17',
 'content': '哪里有同款的郁金香买？',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8545,
 'type': 'pos',
 'user': 'CORSAK_Official'}
2020-05-10 10:58:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '我觉得缺一不可',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.75,
 'type': 'pos',
 'user': '澄澈68069'}
2020-05-10 10:58:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '真好，日常期待8月27号π2，',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6937,
 'type': 'pos',
 'user': '走着鹿_晗着糖'}
2020-05-10 10:58:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8089,
 'type': 'pos',
 'user': 'M逗比比M'}
2020-05-10 10:58:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 哇 期待江洋！太帅了！期待鹿晗',
 'essay_id': 152,
 'fav_nums': '47',
 'label': '上海堡垒',
 'score': 0.777,
 'type': 'pos',
 'user': 'Ai鹿的所有瞬间'}
2020-05-10 10:58:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '第三张鹿鹿太乖啦',
 'essay_id': 0,
 'fav_nums': '60',
 'label': '上海堡垒',
 'score': 0.3537,
 'type': 'neg',
 'user': '鹿晗哥哥我可以'}
2020-05-10 10:58:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.509,
 'type': 'pos',
 'user': '仙鹿hands'}
2020-05-10 10:58:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '啊啊啊  恭喜鹿哥杀青  期待19江洋  鹿哥辛苦了',
 'essay_id': 106,
 'fav_nums': '519',
 'label': '上海堡垒',
 'score': 0.9601,
 'type': 'pos',
 'user': '鹿了个鹿憨憨'}
2020-05-10 10:58:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '虽有遗憾，但任然感激遇见你江洋',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9706,
 'type': 'pos',
 'user': 'Nili_是鹿七岁呀'}
2020-05-10 10:58:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '小江洋好可爱～',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8984,
 'type': 'pos',
 'user': '丫丫-zlh'}
2020-05-10 10:58:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '有人看了吗，是真的很难看吗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6166,
 'type': 'pos',
 'user': 'Aditi-'}
2020-05-10 10:58:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '上海堡垒炸成这样开心吗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6382,
 'type': 'pos',
 'user': '十里长街熙攘'}
2020-05-10 10:58:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404054458995779> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:56 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4407346966722234> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4452214770251759> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404477555352408> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4455546046332498> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '我的天啊每一张都好好看!!!!好甜好甜我晕了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5081,
 'type': 'pos',
 'user': '小鹿晕晕_'}
2020-05-10 10:58:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '啊啊啊啊啊啊，请问是直接跪吗',
 'essay_id': 152,
 'fav_nums': '54',
 'label': '上海堡垒',
 'score': 0.6488,
 'type': 'pos',
 'user': 'yvonneyuuuuuuu'}
2020-05-10 10:58:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '中国版宠物情人可以有吗',
 'essay_id': 0,
 'fav_nums': '55',
 'label': '上海堡垒',
 'score': 0.9478,
 'type': 'pos',
 'user': 'LU西北'}
2020-05-10 10:58:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '回复为图片',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '77一见成欢'}
2020-05-10 10:58:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '替男饭抢个热门',
 'essay_id': 106,
 'fav_nums': '507',
 'label': '上海堡垒',
 'score': 0.9258,
 'type': 'pos',
 'user': '李哒哒鹿'}
2020-05-10 10:58:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '辛苦啦',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.82,
 'type': 'pos',
 'user': 'buuuuunny'}
2020-05-10 10:58:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '清晖月影寒云飞'}
2020-05-10 10:58:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '666',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '戴草帽的麦子'}
2020-05-10 10:58:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '嗷嗷嗷嗷嗷嗷嗷嗷嗷嗷，爱了爱了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7357,
 'type': 'pos',
 'user': '火星上的小仙火'}
2020-05-10 10:58:58 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4470033083931076> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4407346966722234>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:58:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '好看😊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6892,
 'type': 'pos',
 'user': 'M鹿MCatherine'}
2020-05-10 10:58:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '高以翔也非常符合杨建男的设定了',
 'essay_id': 152,
 'fav_nums': '52',
 'label': '上海堡垒',
 'score': 0.9426,
 'type': 'pos',
 'user': 'auoig'}
2020-05-10 10:58:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '俩人好搭',
 'essay_id': 0,
 'fav_nums': '46',
 'label': '上海堡垒',
 'score': 0.8545,
 'type': 'pos',
 'user': '阿鹿士心'}
2020-05-10 10:58:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！新年快乐',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6911,
 'type': 'pos',
 'user': 'nili小玉'}
2020-05-10 10:58:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '出关第一天 期待热血街舞团',
 'essay_id': 106,
 'fav_nums': '404',
 'label': '上海堡垒',
 'score': 0.8316,
 'type': 'pos',
 'user': '迷鹿oba'}
2020-05-10 10:58:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-12-17',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '百丈冰万里凝'}
2020-05-10 10:58:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '可爱的江洋呀',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8206,
 'type': 'pos',
 'user': '芦苇柒柒柒'}
2020-05-10 10:58:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '起码剧情得合理吧乱品乱凑主题和内容偏重不符谁会觉得好',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.0184,
 'type': 'neg',
 'user': '空海悠XS雨轩若尘'}
2020-05-10 10:59:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '看到好几个男生，鹿宝男饭不少呢',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6748,
 'type': 'pos',
 'user': '小鹿乱撞老鹿不撞'}
2020-05-10 10:59:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4468312710429328> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4470033083931076>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可耐',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6034,
 'type': 'pos',
 'user': '檬加璐上'}
2020-05-10 10:59:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '너무 기대된다 따흐흐흐흐흫',
 'essay_id': 152,
 'fav_nums': '37',
 'label': '上海堡垒',
 'score': 0.4477,
 'type': 'neg',
 'user': 'cherishanlu'}
2020-05-10 10:59:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '可爱的鹿5晗本晗',
 'essay_id': 0,
 'fav_nums': '28',
 'label': '上海堡垒',
 'score': 0.7025,
 'type': 'pos',
 'user': '马鹿马不胖'}
2020-05-10 10:59:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '一定会票房大卖',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7905,
 'type': 'pos',
 'user': '任丽晗喜欢鹿晗'}
2020-05-10 10:59:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '送我上去，啊啊啊啊',
 'essay_id': 106,
 'fav_nums': '299',
 'label': '上海堡垒',
 'score': 0.8827,
 'type': 'pos',
 'user': '致爱_777'}
2020-05-10 10:59:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-31',
 'content': '加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9048,
 'type': 'pos',
 'user': '酱啊酱啊酱啊'}
2020-05-10 10:59:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '凌琳儿琳'}
2020-05-10 10:59:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '我感觉导演是责任人，锅推不掉，而且挑演员也是导演必备的功力，挑不好演员还做啥导演',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '求求你快给我推荐昵称吧'}
2020-05-10 10:59:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '辽宁终于有包场可我却来北京旅游了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2523,
 'type': 'neg',
 'user': '哥哥眉上痣'}
2020-05-10 10:59:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4468312710429328>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '好可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '嗯_乖了'}
2020-05-10 10:59:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 表白高以翔',
 'essay_id': 152,
 'fav_nums': '51',
 'label': '上海堡垒',
 'score': 0.3013,
 'type': 'neg',
 'user': 'Sweet_子期'}
2020-05-10 10:59:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '终于有人截p1了',
 'essay_id': 0,
 'fav_nums': '40',
 'label': '上海堡垒',
 'score': 0.4669,
 'type': 'neg',
 'user': '最甜的冰美式'}
2020-05-10 10:59:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新春快乐！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7704,
 'type': 'pos',
 'user': '朝暮心跳'}
2020-05-10 10:59:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '我的江洋哥哥！激动的不会打字了！爱你啊，等你一直等你！ ',
 'essay_id': 106,
 'fav_nums': '269',
 'label': '上海堡垒',
 'score': 0.9893,
 'type': 'pos',
 'user': '小肆的蒹葭苍苍'}
2020-05-10 10:59:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'zhuang燕子1990'}
2020-05-10 10:59:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': ' 好好睡，晚安',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4214,
 'type': 'neg',
 'user': '唯鹿_0420'}
2020-05-10 10:59:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '营销号又在乱带节奏了，为了点流量去毁了一个导演，良心不会痛吗？',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1566,
 'type': 'neg',
 'user': '宋小爬i'}
2020-05-10 10:59:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '哇啊啊啊不在大连啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8201,
 'type': 'pos',
 'user': '西柚珉xiuxiu'}
2020-05-10 10:59:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可爱鬼',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8814,
 'type': 'pos',
 'user': '精神鹅崽不请自来'}
2020-05-10 10:59:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 被杨指挥官帅哭！爆灯！疯狂打 call ',
 'essay_id': 152,
 'fav_nums': '47',
 'label': '上海堡垒',
 'score': 0.9802,
 'type': 'pos',
 'user': '錦素悠然-G'}
2020-05-10 10:59:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '期待俩姐弟',
 'essay_id': 0,
 'fav_nums': '25',
 'label': '上海堡垒',
 'score': 0.783,
 'type': 'pos',
 'user': '阿鹿士心'}
2020-05-10 10:59:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '预祝',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '晗崽温柔陷阱'}
2020-05-10 10:59:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '期待江洋哥哥！',
 'essay_id': 106,
 'fav_nums': '217',
 'label': '上海堡垒',
 'score': 0.9857,
 'type': 'pos',
 'user': '扒圈老鬼'}
2020-05-10 10:59:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '❤',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '春花秋色777'}
2020-05-10 10:59:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '可爱的江洋',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8206,
 'type': 'pos',
 'user': '爱鹿晗和蔡徐坤的猪猪'}
2020-05-10 10:59:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '做重要是导演  因为导演是这个剧／电影的中心  剧本 演员  都得是导演来挑选   非常考验导演眼光  能力     '
            '说这个演员演技行不行  适不适合这个角色      虽说演员演技有好有坏  那最后敲板不是导演吗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '薄荷uo'}
2020-05-10 10:59:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-27',
 'content': '真的是快乐的一天',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.936,
 'type': 'pos',
 'user': 'M晗影M'}
2020-05-10 10:59:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404092698693640> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可爱啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8089,
 'type': 'pos',
 'user': '任丽晗喜欢鹿晗'}
2020-05-10 10:59:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 超级期待！高以翔新作指挥官的角色',
 'essay_id': 152,
 'fav_nums': '45',
 'label': '上海堡垒',
 'score': 0.9856,
 'type': 'pos',
 'user': '土豆Wang琼'}
2020-05-10 10:59:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '我真的get到了cp感！！！会有江洋哥哥醉酒跟林澜姐姐耍酒疯表心意的那一幕吗',
 'essay_id': 0,
 'fav_nums': '30',
 'label': '上海堡垒',
 'score': 0.9915,
 'type': 'pos',
 'user': '哒哒哒哒桥小鹿'}
2020-05-10 10:59:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8158,
 'type': 'pos',
 'user': '阿衡的妖精大人'}
2020-05-10 10:59:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '辛苦了，江洋，2019见',
 'essay_id': 106,
 'fav_nums': '189',
 'label': '上海堡垒',
 'score': 0.7146,
 'type': 'pos',
 'user': 'LH7-M琪M'}
2020-05-10 10:59:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '参加了两场，反正一切只为鹿晗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4708,
 'type': 'neg',
 'user': '鹿晗你自己圆'}
2020-05-10 10:59:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱的江洋',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.887,
 'type': 'pos',
 'user': 'chenchen欤兮'}
2020-05-10 10:59:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '开始甩锅了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2618,
 'type': 'neg',
 'user': '一分钟要原谅他八百遍'}
2020-05-10 10:59:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-26',
 'content': '鹿晗6000万粉丝，目前《上海堡垒》票房1.2亿，按40元一张票，才300万人观看，也就是说只有5%的鹿晗粉丝在支持，我想问问剩下95%的鹿晗粉丝们，你们不想看的原因，在哪里？是故事情节烂？还是鹿晗表演烂？还是导演水平烂？',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.0049,
 'type': 'neg',
 'user': '浪漫793'}
2020-05-10 10:59:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': ' P4呜呜呜呜 你撒撒娇 我心都化了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9697,
 'type': 'pos',
 'user': '傅可爱鹿柒'}
2020-05-10 10:59:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '哦妈呀，高以翔扮演杨建南！！！我以前看胜女的代价迷过他一阵，他真的很适合这个角色',
 'essay_id': 152,
 'fav_nums': '46',
 'label': '上海堡垒',
 'score': 0.9996,
 'type': 'pos',
 'user': '养生少女爱熬夜'}
2020-05-10 10:59:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '小鹿害羞了',
 'essay_id': 0,
 'fav_nums': '20',
 'label': '上海堡垒',
 'score': 0.4763,
 'type': 'neg',
 'user': '鹿晗你个大猪蹄子wan'}
2020-05-10 10:59:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '期待上海堡垒！新年快乐！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7643,
 'type': 'pos',
 'user': '芝士小鹿_Reh'}
2020-05-10 10:59:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '想把你捧在手心',
 'essay_id': 106,
 'fav_nums': '204',
 'label': '上海堡垒',
 'score': 0.5261,
 'type': 'pos',
 'user': '温柔De铠甲'}
2020-05-10 10:59:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '我参与了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.75,
 'type': 'pos',
 'user': '咙咚哩咯呛'}
2020-05-10 10:59:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'rua星球访客登记簿'}
2020-05-10 10:59:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '怪林俊杰谁叫他唱了江南。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9271,
 'type': 'pos',
 'user': 'DASKLIS'}
2020-05-10 10:59:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'WFLHLMH'}
2020-05-10 10:59:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4425100163674276> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4415531161340376> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4413609473803461> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4465755779581713> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4468014626157609> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '果然露点头发更好看了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8862,
 'type': 'pos',
 'user': '憨与摩托车维修艺术'}
2020-05-10 10:59:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '2019等你 杨指挥官',
 'essay_id': 152,
 'fav_nums': '48',
 'label': '上海堡垒',
 'score': 0.7715,
 'type': 'pos',
 'user': '白云的侬'}
2020-05-10 10:59:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': ' 第一张好A阿！！',
 'essay_id': 0,
 'fav_nums': '21',
 'label': '上海堡垒',
 'score': 0.3476,
 'type': 'neg',
 'user': '七鹿娃'}
2020-05-10 10:59:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5155,
 'type': 'pos',
 'user': '沫熙梓啊'}
2020-05-10 10:59:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': ' 杀青快乐',
 'essay_id': 106,
 'fav_nums': '182',
 'label': '上海堡垒',
 'score': 0.9438,
 'type': 'pos',
 'user': '鹿安唯'}
2020-05-10 10:59:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '风里雨里我们一起负重前行。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8809,
 'type': 'pos',
 'user': '骑着蜗牛的微笑'}
2020-05-10 10:59:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '鹿晗小胡子'}
2020-05-10 10:59:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '这导演是在炒作么？！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.0204,
 'type': 'neg',
 'user': '関門閊'}
2020-05-10 10:59:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '极点点点点点'}
2020-05-10 10:59:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4417610500627067> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4465755779581713>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4468014626157609>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-7',
 'content': '笑起来简直绝了好吗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5444,
 'type': 'pos',
 'user': '饼饼要快乐哟'}
2020-05-10 10:59:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待高以翔高七帅的精彩演出',
 'essay_id': 152,
 'fav_nums': '43',
 'label': '上海堡垒',
 'score': 0.9721,
 'type': 'pos',
 'user': '龙飞伟翔'}
2020-05-10 10:59:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '人美心善',
 'essay_id': 0,
 'fav_nums': '18',
 'label': '上海堡垒',
 'score': 0.9175,
 'type': 'pos',
 'user': 'Secret_girl'}
2020-05-10 10:59:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7056,
 'type': 'pos',
 'user': '可爱的夏爷'}
2020-05-10 10:59:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '你这样不好',
 'essay_id': 106,
 'fav_nums': '169',
 'label': '上海堡垒',
 'score': 0.2451,
 'type': 'neg',
 'user': 'M鱼梦M'}
2020-05-10 10:59:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '还有各个群自己组织的包场也很多',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5868,
 'type': 'pos',
 'user': '小玉娘'}
2020-05-10 10:59:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '郁金香消失了吗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.901,
 'type': 'pos',
 'user': '山的那边Lee'}
2020-05-10 10:59:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '看预告，特效还好',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.835,
 'type': 'pos',
 'user': '阿翡的窄背刀'}
2020-05-10 10:59:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'CherryCarry_'}
2020-05-10 10:59:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4382422000763891> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-6',
 'content': '奶黄包',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9618,
 'type': 'pos',
 'user': '昏喵与鹿'}
2020-05-10 10:59:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '妈呀，高以翔演杨建南！',
 'essay_id': 152,
 'fav_nums': '43',
 'label': '上海堡垒',
 'score': 0.9697,
 'type': 'pos',
 'user': 'TeteJuaner'}
2020-05-10 10:59:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '哈哈',
 'essay_id': 0,
 'fav_nums': '17',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '上官熊熊123'}
2020-05-10 10:59:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7056,
 'type': 'pos',
 'user': 'Deer甜reeD'}
2020-05-10 10:59:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122258228984>
{'add_time': '2017-12-20',
 'content': '啊啊啊啊啊啊，一天两博！！！！出关了就不一样，我活过来了啊',
 'essay_id': 106,
 'fav_nums': '165',
 'label': '上海堡垒',
 'score': 0.4642,
 'type': 'neg',
 'user': '高贵的路人甲丙丁'}
2020-05-10 10:59:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '里面有我的一份  特别开心',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8291,
 'type': 'pos',
 'user': '你的阿七y'}
2020-05-10 10:59:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '我小江好乖妈呀',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8892,
 'type': 'pos',
 'user': '我要去三巡啊'}
2020-05-10 10:59:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '有多少没有看到最后选项而后悔的？心急总误事，大热天要淡定啊～',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.0773,
 'type': 'neg',
 'user': '開森大牛'}
2020-05-10 10:59:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '【鹿晗吧辽宁分会包场第二场-大连】热血常燃，无畏前行，因爱集结，予鹿勋章[加油][加油][加油]',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '伱偌卟离555'}
2020-05-10 10:59:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '-鹿鹿鹿鹿鹿lu'}
2020-05-10 10:59:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 杨建南指挥官',
 'essay_id': 152,
 'fav_nums': '40',
 'label': '上海堡垒',
 'score': 0.9382,
 'type': 'pos',
 'user': '高以翔吧官方微博'}
2020-05-10 10:59:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '第三张奶鹿鹿',
 'essay_id': 0,
 'fav_nums': '16',
 'label': '上海堡垒',
 'score': 0.2915,
 'type': 'neg',
 'user': '心动7号男嘉宾鹿晗'}
2020-05-10 10:59:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7046,
 'type': 'pos',
 'user': '为梦想而生的小青年'}
2020-05-10 10:59:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '夹缝中找自己，然后…放弃了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2992,
 'type': 'neg',
 'user': '芦苇如儿'}
2020-05-10 10:59:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '我们小江',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4903,
 'type': 'neg',
 'user': 'L小果的少女心7'}
2020-05-10 10:59:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '缺一不可',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.75,
 'type': 'pos',
 'user': '时光叫我别鸟他ing'}
2020-05-10 10:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '我喜欢的样子正好你都有'}
2020-05-10 10:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '七月鹿过遇见晗'}
2020-05-10 10:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待鹿晗',
 'essay_id': 152,
 'fav_nums': '31',
 'label': '上海堡垒',
 'score': 0.6423,
 'type': 'pos',
 'user': '千里送逼的关泰迪'}
2020-05-10 10:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '鹿晗鹿晗',
 'essay_id': 0,
 'fav_nums': '10',
 'label': '上海堡垒',
 'score': 0.4219,
 'type': 'neg',
 'user': '鹿卢鹿不羁0420'}
2020-05-10 10:59:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': ' 新年快乐 上海堡垒票房大卖',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8317,
 'type': 'pos',
 'user': 'M梓沁的枕头M'}
2020-05-10 10:59:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'Look_Here_777'}
2020-05-10 10:59:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '余生有果果酱'}
2020-05-10 10:59:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '向→有病？人家怪鹿晗了？',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2286,
 'type': 'neg',
 'user': '谷雪dd'}
2020-05-10 10:59:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '我喜欢的样子正好你都有'}
2020-05-10 10:59:20 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4457158055895490> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '一切美好的事物结识你',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8797,
 'type': 'pos',
 'user': '山间鹿鸣er'}
2020-05-10 10:59:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#高以翔# 期待看到杨指挥官，看到国民男神高以翔👍',
 'essay_id': 152,
 'fav_nums': '42',
 'label': '上海堡垒',
 'score': 0.7056,
 'type': 'pos',
 'user': '北京大杨宝'}
2020-05-10 10:59:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '青砚不蛊'}
2020-05-10 10:59:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7056,
 'type': 'pos',
 'user': '红树林588'}
2020-05-10 10:59:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '不说再见，我们一起向前进',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4008,
 'type': 'neg',
 'user': '芦苇deer柒七'}
2020-05-10 10:59:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱，我们江司令',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8486,
 'type': 'pos',
 'user': '不是鹿过哦哈哟'}
2020-05-10 10:59:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '3',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.3901,
 'type': 'neg',
 'user': 'ahaiHi24411'}
2020-05-10 10:59:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': '加油小堡贝',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9625,
 'type': 'pos',
 'user': '维妳喜欢鹿晗'}
2020-05-10 10:59:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4457158055895490>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '上海堡垒冲呀',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4297,
 'type': 'neg',
 'user': '奈肴迦茶_'}
2020-05-10 10:59:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '表白高以翔',
 'essay_id': 152,
 'fav_nums': '38',
 'label': '上海堡垒',
 'score': 0.3013,
 'type': 'neg',
 'user': '曦诺xinuo'}
2020-05-10 10:59:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '期待鹿晗',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.6423,
 'type': 'pos',
 'user': '鹿卢鹿不羁0420'}
2020-05-10 10:59:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '👏👏👏',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '青懒惰'}
2020-05-10 10:59:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': ' 陪你闯天下💛',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5512,
 'type': 'pos',
 'user': '晗很爱你'}
2020-05-10 10:59:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '小可爱江洋 ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8221,
 'type': 'pos',
 'user': '小青菇'}
2020-05-10 10:59:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '特效还是可以的，就是剧本和演技',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8949,
 'type': 'pos',
 'user': '日常催更小使者'}
2020-05-10 10:59:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4406931189701602>
{'add_time': '2019-8-19',
 'content': ' 开心',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7429,
 'type': 'pos',
 'user': 'M晗影M'}
2020-05-10 10:59:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4382419128123955> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:24 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4404054458995779> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:24 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4404477555352408> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:24 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4455546046332498> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:24 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4452214770251759> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '甜度满分',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7298,
 'type': 'pos',
 'user': '夏日的奇遇_'}
2020-05-10 10:59:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '杨建南指挥官 帅型高七帅 喊破喉咙为你打call',
 'essay_id': 152,
 'fav_nums': '37',
 'label': '上海堡垒',
 'score': 0.9866,
 'type': 'pos',
 'user': '钦仰脆'}
2020-05-10 10:59:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '咻咻咻，嘿嘿，鹿晗看我看我',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.1803,
 'type': 'neg',
 'user': 'dear鈺珺'}
2020-05-10 10:59:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7056,
 'type': 'pos',
 'user': '小贸176mm'}
2020-05-10 10:59:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '    很棒的大家庭',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9719,
 'type': 'pos',
 'user': '瑶瑶的鹿晗哥哥'}
2020-05-10 10:59:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': ' 可爱可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9416,
 'type': 'pos',
 'user': '晨鹿萌鹿惟鹿'}
2020-05-10 10:59:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '演员这两个字好多娱乐圈里的人都算不上吧，还以为是郭敬明的粉丝票房时代？',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9997,
 'type': 'pos',
 'user': '小卢一定要减肥成功嗷'}
2020-05-10 10:59:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4382423544716262> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4404054458995779>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4404477555352408>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4455546046332498>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4452214770251759>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可可爱爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9189,
 'type': 'pos',
 'user': '搞晗玩家'}
2020-05-10 10:59:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '哇，期待早日看到你的杨建南',
 'essay_id': 152,
 'fav_nums': '36',
 'label': '上海堡垒',
 'score': 0.9528,
 'type': 'pos',
 'user': 'sheep兔'}
2020-05-10 10:59:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '上海堡垒江洋这波必须拿第一啊~',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.845,
 'type': 'pos',
 'user': 'dear鈺珺'}
2020-05-10 10:59:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '预祝票房大卖',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7524,
 'type': 'pos',
 'user': '果妈15815'}
2020-05-10 10:59:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '百度鹿晗吧，陪你闯天下[加油][加油][加油]',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.998,
 'type': 'pos',
 'user': 'Dawn-Snow'}
2020-05-10 10:59:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '想为这样的小江承包整片郁金香海洋，和所有夜晚的“好好睡，晚安”',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4706,
 'type': 'neg',
 'user': '伱偌卟离555'}
2020-05-10 10:59:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '我觉得一部好的电影需要有一个好的剧情外加会演戏的演员而不是所谓的“流量明星”',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9974,
 'type': 'pos',
 'user': '傲娇腹黑妮可酱'}
2020-05-10 10:59:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4405301597505334> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可爱死了！！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.412,
 'type': 'neg',
 'user': '鹿晗工作室的废物滚蛋了吗'}
2020-05-10 10:59:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '军装高，你帅哭我了',
 'essay_id': 152,
 'fav_nums': '35',
 'label': '上海堡垒',
 'score': 0.7705,
 'type': 'pos',
 'user': '龙飞伟翔'}
2020-05-10 10:59:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '图五视频里舒淇姐姐好像还说了“你怎么这么乖啊”',
 'essay_id': 0,
 'fav_nums': '11',
 'label': '上海堡垒',
 'score': 0.8542,
 'type': 'pos',
 'user': '乡野村夫陈长生'}
2020-05-10 10:59:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '预祝票房大卖',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7524,
 'type': 'pos',
 'user': '大吉大利-777'}
2020-05-10 10:59:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9048,
 'type': 'pos',
 'user': 'W萱X'}
2020-05-10 10:59:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '这个配图我给满分',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7298,
 'type': 'pos',
 'user': '香橙兔子和看热闹的猫'}
2020-05-10 10:59:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '这导演   自己当初干嘛去了    现在怪这个怪那个   自己不行   怨别人',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1485,
 'type': 'neg',
 'user': 'So__Lucky'}
2020-05-10 10:59:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可可爱爱！！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8192,
 'type': 'pos',
 'user': '士多啤梨晶Lulu'}
2020-05-10 10:59:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '打卡#鹿晗#',
 'essay_id': 152,
 'fav_nums': '19',
 'label': '上海堡垒',
 'score': 0.068,
 'type': 'neg',
 'user': 'M玉佳'}
2020-05-10 10:59:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '我170在我们学校，男生都比我高不了多少，178绝对够用，男神身高了好吧，还说矮，原来大家人均身高都185的嘛？',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.8148,
 'type': 'pos',
 'user': '猛男就要穿粉色'}
2020-05-10 10:59:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '预祝票房大卖',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7524,
 'type': 'pos',
 'user': '沫鹿Sun'}
2020-05-10 10:59:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '亲亲七七宝呀'}
2020-05-10 10:59:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '阔爱啊，为你打call😭',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7067,
 'type': 'pos',
 'user': '对你不羁的爱'}
2020-05-10 10:59:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '俞小囡n'}
2020-05-10 10:59:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '都好帅都好帅啊啊啊啊啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8893,
 'type': 'pos',
 'user': '鹿晗的要求我都满足'}
2020-05-10 10:59:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '恭喜恭喜',
 'essay_id': 152,
 'fav_nums': '20',
 'label': '上海堡垒',
 'score': 0.8901,
 'type': 'pos',
 'user': '鹿先森的小娘子'}
2020-05-10 10:59:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '这个热搜怎么那么爽呢？？？',
 'essay_id': 0,
 'fav_nums': '11',
 'label': '上海堡垒',
 'score': 0.1219,
 'type': 'neg',
 'user': '我要去三巡啊'}
2020-05-10 10:59:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '好的好的',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7658,
 'type': 'pos',
 'user': '听妈妈说微博名字不可以太长'}
2020-05-10 10:59:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '真棒',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': 'M小鹿仙倌M'}
2020-05-10 10:59:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '很棒',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8649,
 'type': 'pos',
 'user': '霸气的鹿晗吖'}
2020-05-10 10:59:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '前生往世1'}
2020-05-10 10:59:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4404092698693640> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '啊啊啊啊啊啊啊好好看',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9708,
 'type': 'pos',
 'user': 'Andy小朋友的糖果'}
2020-05-10 10:59:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '感谢导演！感谢我们的团队！让我有了一次非凡的经历。已经迫不及待要走进电影院了',
 'essay_id': 152,
 'fav_nums': '12',
 'label': '上海堡垒',
 'score': 0.9938,
 'type': 'pos',
 'user': '王宫良'}
2020-05-10 10:59:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '好吧我承认鹿晗很美比一般女生还要好看  但是不能这样就说人家娘了',
 'essay_id': 0,
 'fav_nums': '10',
 'label': '上海堡垒',
 'score': 0.9697,
 'type': 'pos',
 'user': '欧阳秀秀mj'}
2020-05-10 10:59:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐🎉🎉',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6833,
 'type': 'pos',
 'user': 'Quiana_Ma'}
2020-05-10 10:59:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '謎妹電量不足'}
2020-05-10 10:59:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '江洋加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9112,
 'type': 'pos',
 'user': 'pink筱雪'}
2020-05-10 10:59:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '岁月不在2003'}
2020-05-10 10:59:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4404092698693640>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 10:59:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '可可爱爱！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9189,
 'type': 'pos',
 'user': 'PlutoMuseum'}
2020-05-10 10:59:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '杀青快乐 辛苦啦 期待电影的上映 期待江洋哥哥',
 'essay_id': 152,
 'fav_nums': '18',
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '爱笃信的鹿小姐'}
2020-05-10 10:59:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '帅哥美女真养眼',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.9984,
 'type': 'pos',
 'user': '我的彼得潘小王子'}
2020-05-10 10:59:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '一定要去看',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5748,
 'type': 'pos',
 'user': '美羊羊199008'}
2020-05-10 10:59:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '转发微博',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6439,
 'type': 'pos',
 'user': '白鹿晗'}
2020-05-10 10:59:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '可爱！！！！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5316,
 'type': 'pos',
 'user': '易子鹿'}
2020-05-10 10:59:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '一部抗战片，就应该接近过去，学下亮剑，那才是真正的抗日战争片，观众不想看美化过头的，那不如看好莱坞，接近历史贴近生活，还原过去才能好看',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': 'silenc_儍'}
2020-05-10 10:59:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'Andy剧中人'}
2020-05-10 10:59:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '表白江洋哥哥',
 'essay_id': 152,
 'fav_nums': '15',
 'label': '上海堡垒',
 'score': 0.9264,
 'type': 'pos',
 'user': '呼啊呼啊啊啊啊嚏'}
2020-05-10 10:59:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿晗你敢不敢直视一下姐姐哈哈哈哈',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.8334,
 'type': 'pos',
 'user': '宇红今天同框了吗'}
2020-05-10 10:59:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '咋都没见宣传啊！差点以为不放了',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.013,
 'type': 'neg',
 'user': '美羊羊199008'}
2020-05-10 10:59:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '一鹿伴晗',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4738,
 'type': 'neg',
 'user': '一朵云中的蒲公英'}
2020-05-10 10:59:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱啊。我们的江江。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8486,
 'type': 'pos',
 'user': '冬日鹿遇晗光'}
2020-05-10 10:59:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '过得去的素质加了不起的营销就行',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4389,
 'type': 'neg',
 'user': '臭脾气大叔一一改'}
2020-05-10 10:59:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4417610500627067> (referer: None)
2020-05-10 10:59:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403154919372286> (referer: None)
2020-05-10 10:59:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4415531161340376> (referer: None)
2020-05-10 10:59:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4425100163674276> (referer: None)
2020-05-10 10:59:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4413609473803461> (referer: None)
2020-05-10 10:59:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '太好看了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5375,
 'type': 'pos',
 'user': '迷M鹿M420'}
2020-05-10 10:59:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#鹿晗# 恭喜杀青！辛苦了各位演职人员！最后表白我鹿！',
 'essay_id': 152,
 'fav_nums': '16',
 'label': '上海堡垒',
 'score': 0.1926,
 'type': 'neg',
 'user': '行走凋零处'}
2020-05-10 10:59:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '你别说，这个有点林澜和江洋的感觉',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.6277,
 'type': 'pos',
 'user': '朗佐ball2'}
2020-05-10 10:59:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '除夕快乐！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9438,
 'type': 'pos',
 'user': '安哥拉兔的兔兔毛'}
2020-05-10 10:59:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '鹿家小吃货_'}
2020-05-10 10:59:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '小江找不到林澜了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.3291,
 'type': 'neg',
 'user': '曼听花园'}
2020-05-10 10:59:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '111',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.25,
 'type': 'neg',
 'user': '籹囚丶伱夲該驕傲71320'}
2020-05-10 10:59:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '小可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8105,
 'type': 'pos',
 'user': 'M_May520'}
2020-05-10 10:59:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待我们杨指挥官',
 'essay_id': 152,
 'fav_nums': '25',
 'label': '上海堡垒',
 'score': 0.8821,
 'type': 'pos',
 'user': '渴渴渴'}
2020-05-10 10:59:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '因为原著江洋就和林澜差不多高啊，而且鹿晗178不矮了叭',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.2312,
 'type': 'neg',
 'user': '猛男就要穿粉色'}
2020-05-10 10:59:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '转发微博',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6439,
 'type': 'pos',
 'user': '专属傻狍子'}
2020-05-10 10:59:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '一起一直陪你闯天下',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.577,
 'type': 'pos',
 'user': '7_LH7'}
2020-05-10 10:59:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '//',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2,
 'type': 'neg',
 'user': '薰衣草田11'}
2020-05-10 10:59:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。。',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.4768,
 'type': 'neg',
 'user': '书上落叶'}
2020-05-10 10:59:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4382419128123955> (referer: None)
2020-05-10 10:59:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402357448496525> (referer: None)
2020-05-10 10:59:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4382423544716262> (referer: None)
2020-05-10 10:59:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4400031354534112> (referer: None)
2020-05-10 10:59:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4382422000763891> (referer: None)
2020-05-10 10:59:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4417610500627067", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:59:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 10:59:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:59:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4417610500627067> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 10:59:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403154919372286", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:59:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 10:59:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:59:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403154919372286> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 10:59:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4415531161340376", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:59:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 10:59:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:59:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4415531161340376> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 10:59:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4425100163674276", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 10:59:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 10:59:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 10:59:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4425100163674276> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 10:59:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4413609473803461", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4413609473803461> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '太好看了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5375,
 'type': 'pos',
 'user': 'Number7_pilot'}
2020-05-10 11:00:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '不是以粉丝说话，我看了原著，非常喜欢，我觉得导演选的这三个角色真的和我看书时想像的角色非常像，导演好眼力，非常期待这部电影',
 'essay_id': 152,
 'fav_nums': '16',
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '半熟少女swag'}
2020-05-10 11:00:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '这是今晚第22届电影节现场直播，鹿晗和舒淇在舞台上，明天可以在腾讯视频看回放。',
 'essay_id': 0,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.2561,
 'type': 'neg',
 'user': '大大小丸孑'}
2020-05-10 11:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '除夕快乐！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9438,
 'type': 'pos',
 'user': 'swm3773'}
2020-05-10 11:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '辛苦辛苦！晚安',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9688,
 'type': 'pos',
 'user': '阿鹿的小居居'}
2020-05-10 11:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-17',
 'content': '//',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2,
 'type': 'neg',
 'user': '李李5998207952'}
2020-05-10 11:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '本来想看，结果一看评论，还是打住了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6432,
 'type': 'pos',
 'user': '殇颜201711'}
2020-05-10 11:00:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405301597505334> (referer: None)
2020-05-10 11:00:02 [scrapy.extensions.logstats] INFO: Crawled 35 pages (at 11 pages/min), scraped 555 items (at 239 items/min)
2020-05-10 11:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '哇！哥哥笑得好甜',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9971,
 'type': 'pos',
 'user': '七炁兮'}
2020-05-10 11:00:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '你们辛苦了，2019年期待我们的江洋上线',
 'essay_id': 152,
 'fav_nums': '13',
 'label': '上海堡垒',
 'score': 0.8981,
 'type': 'pos',
 'user': 'llanooooo'}
2020-05-10 11:00:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '这几张图我能get到鹿晗的帅了',
 'essay_id': 0,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.3586,
 'type': 'neg',
 'user': '植树的眼睛'}
2020-05-10 11:00:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7056,
 'type': 'pos',
 'user': '蔡徐坤的小仙女k'}
2020-05-10 11:00:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '晚安',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6486,
 'type': 'pos',
 'user': '一阵_M鹿风M'}
2020-05-10 11:00:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱又帅气的鹿哥，图我拿走啦',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8425,
 'type': 'pos',
 'user': 'L鹿Z'}
2020-05-10 11:00:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '千山旧'}
2020-05-10 11:00:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404181638657441> (referer: None)
2020-05-10 11:00:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404219425178682> (referer: None)
2020-05-10 11:00:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404218842179533> (referer: None)
2020-05-10 11:00:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4411565698964476> (referer: None)
2020-05-10 11:00:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4410409333161068> (referer: None)
2020-05-10 11:00:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4402732469400747> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:00:04 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4382419128123955", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4382419128123955> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:08 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402357448496525", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402357448496525> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4382423544716262", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4382423544716262> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4400031354534112", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4400031354534112> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4382422000763891", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4382422000763891> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '啊啊啊啊最后那个笑啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9445,
 'type': 'pos',
 'user': '鹿溪溪l'}
2020-05-10 11:00:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待江洋',
 'essay_id': 152,
 'fav_nums': '12',
 'label': '上海堡垒',
 'score': 0.7053,
 'type': 'pos',
 'user': '-琥珀-_-h_h'}
2020-05-10 11:00:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '这俩好好玩哈哈哈哈',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.7415,
 'type': 'pos',
 'user': '双向星河'}
2020-05-10 11:00:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '加油',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9048,
 'type': 'pos',
 'user': '蔡徐坤的小仙女k'}
2020-05-10 11:00:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': ' 辛苦了大吧',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8234,
 'type': 'pos',
 'user': '无梦不做的棒棒Andy'}
2020-05-10 11:00:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '我们的江洋',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5455,
 'type': 'pos',
 'user': '晓莉云图'}
2020-05-10 11:00:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '是个好片子 但是主角儿不太合适',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9806,
 'type': 'pos',
 'user': '且看勿多言丶'}
2020-05-10 11:00:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403054646614778> (failed 1 times): 504 Gateway Time-out
2020-05-10 11:00:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4407308995869223> (failed 1 times): 502 Bad Gateway
2020-05-10 11:00:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405301597505334", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405301597505334> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '啊啊啊啊啊啊，好看啊',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9798,
 'type': 'pos',
 'user': '77个小萌豆'}
2020-05-10 11:00:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#鹿晗上海堡垒# 恭喜杀青',
 'essay_id': 152,
 'fav_nums': '10',
 'label': '上海堡垒',
 'score': 0.118,
 'type': 'neg',
 'user': '等一丢丢快乐'}
2020-05-10 11:00:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '帅气姐弟总是那么惹眼',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.9651,
 'type': 'pos',
 'user': '小月半orange'}
2020-05-10 11:00:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '票房大卖！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7715,
 'type': 'pos',
 'user': '江南晚栀'}
2020-05-10 11:00:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '辛苦了…一起陪着鹿晗闯天下[加油][加油][加油]',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9994,
 'type': 'pos',
 'user': '嫚Nini'}
2020-05-10 11:00:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-20',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': 'LH7鹿若安好便是晴天'}
2020-05-10 11:00:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '一部好电影需要很多很多的努力',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9792,
 'type': 'pos',
 'user': '沐七七的沐'}
2020-05-10 11:00:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403683012060660> (referer: None)
2020-05-10 11:00:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402732469400747> (referer: None)
2020-05-10 11:00:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404181638657441", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404181638657441> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404219425178682", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404219425178682> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404218842179533", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404218842179533> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4411565698964476", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4411565698964476> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4410409333161068", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4410409333161068> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-5',
 'content': '好看呀',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7112,
 'type': 'pos',
 'user': '撬不走的钉子户'}
2020-05-10 11:00:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#高以翔电影上海堡垒#    期待2019年，期待帅气的杨建南',
 'essay_id': 152,
 'fav_nums': '23',
 'label': '上海堡垒',
 'score': 0.9968,
 'type': 'pos',
 'user': '高以翔空间站'}
2020-05-10 11:00:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '帅气姐弟，太震撼了',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.9494,
 'type': 'pos',
 'user': 'dear鈺珺'}
2020-05-10 11:00:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8158,
 'type': 'pos',
 'user': '鹿晗说我不胖'}
2020-05-10 11:00:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '陪你闯天下',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.577,
 'type': 'pos',
 'user': 'LH7梦鹿三巡'}
2020-05-10 11:00:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-19',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '鹿家七少'}
2020-05-10 11:00:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '芥末和薄荷'}
2020-05-10 11:00:53 [scrapy.extensions.logstats] INFO: Crawled 42 pages (at 7 pages/min), scraped 583 items (at 28 items/min)
2020-05-10 11:00:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-10',
 'content': '哥哥加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9964,
 'type': 'pos',
 'user': 'Superlit_不争'}
2020-05-10 11:00:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#高以翔上海堡垒#  向帅气的指挥官敬礼， ',
 'essay_id': 152,
 'fav_nums': '18',
 'label': '上海堡垒',
 'score': 0.0756,
 'type': 'neg',
 'user': '格式化XXXGodfrey'}
2020-05-10 11:00:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '完全就是姐姐弟弟',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.8375,
 'type': 'pos',
 'user': '双向星河'}
2020-05-10 11:00:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '新年快乐，猪年大吉',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2446,
 'type': 'neg',
 'user': '留白记忆7'}
2020-05-10 11:00:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '你是远方星球的引力，所以我潮汐不止',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9826,
 'type': 'pos',
 'user': '咖喱鹿z'}
2020-05-10 11:00:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-17',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '我是一道数学压轴题'}
2020-05-10 11:00:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '这种白痴一样的投票以后就不要搞了好伐',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2505,
 'type': 'neg',
 'user': '斯拉夫波紋疾走'}
2020-05-10 11:00:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403683012060660", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:00:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:00:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:00:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403683012060660> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:00:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402732469400747", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:01:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:01:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:01:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402732469400747> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:01:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-6',
 'content': '这套图！！！！！！我好爱！！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.146,
 'type': 'neg',
 'user': '好香一只蹄'}
2020-05-10 11:01:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#高以翔上海堡垒# 向指挥官敬礼，长官好！ ',
 'essay_id': 152,
 'fav_nums': '16',
 'label': '上海堡垒',
 'score': 0.1171,
 'type': 'neg',
 'user': '格式化XXXGodfrey'}
2020-05-10 11:01:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '姐弟俩太可爱了哈哈哈',
 'essay_id': 0,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.9508,
 'type': 'pos',
 'user': '双向星河'}
2020-05-10 11:01:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-5',
 'content': '鹿晗堆塔数据群恭祝鹿晗新春快乐！预祝《上海堡垒》票房大卖！！！新年快乐',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6911,
 'type': 'pos',
 'user': '这就是我7777777'}
2020-05-10 11:01:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-20',
 'content': '虽然没有一个很好的结果，但我们都曾经用心的经历了，π2加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9986,
 'type': 'pos',
 'user': '米拉多小姐mm'}
2020-05-10 11:01:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '  可爱江江',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7568,
 'type': 'pos',
 'user': '飘过的熊'}
2020-05-10 11:01:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '202616144hIhSW'}
2020-05-10 11:01:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403681724019810> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403054646614778> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4407308995869223> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4402012919971507>
{'add_time': '2019-8-6',
 'content': '太甜了太甜了 治愈',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7086,
 'type': 'pos',
 'user': '原生态鹿'}
2020-05-10 11:01:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ': #高以翔电影上海堡垒#   期待杨建南指挥官',
 'essay_id': 152,
 'fav_nums': '17',
 'label': '上海堡垒',
 'score': 0.9136,
 'type': 'pos',
 'user': '细雨静飘逸'}
2020-05-10 11:01:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '啊热搜',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.2107,
 'type': 'neg',
 'user': '慕薇Alice'}
2020-05-10 11:01:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4336066754827248>
{'add_time': '2019-2-4',
 'content': '回复为图片',
 'essay_id': 83,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'Manaing'}
2020-05-10 11:01:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '好好睡，晚安！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4214,
 'type': 'neg',
 'user': '脆弱的静语333'}
2020-05-10 11:01:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '彧綰蘇'}
2020-05-10 11:01:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '缺一不可的',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.75,
 'type': 'pos',
 'user': '秦岭神树老九门'}
2020-05-10 11:01:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403674623510025> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '帅气的指挥官高以翔 #全世界最好的高以翔#  ',
 'essay_id': 152,
 'fav_nums': '17',
 'label': '上海堡垒',
 'score': 0.8805,
 'type': 'pos',
 'user': '格式化XXXGodfrey'}
2020-05-10 11:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '晗晗多看看漂亮姐姐吧',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9528,
 'type': 'pos',
 'user': '是小王子鹿晗啊'}
2020-05-10 11:01:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': ' 看到自己了，鹿晗加油！我们永远都在',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9439,
 'type': 'pos',
 'user': '鹿鹿彩虹酱在劫难逃'}
2020-05-10 11:01:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '哇，可爱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8089,
 'type': 'pos',
 'user': '鹿哈96'}
2020-05-10 11:01:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '用排除法，首先不能有小鲜肉',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.616,
 'type': 'pos',
 'user': 'Tahaha哈哈'}
2020-05-10 11:01:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#高以翔上海堡垒#  完美的男人 完美的指挥官',
 'essay_id': 152,
 'fav_nums': '15',
 'label': '上海堡垒',
 'score': 0.7213,
 'type': 'pos',
 'user': '格式化XXXGodfrey'}
2020-05-10 11:01:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '好奶好可爱',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.8673,
 'type': 'pos',
 'user': '_KU_KI_NA_KU_'}
2020-05-10 11:01:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'LH婷7'}
2020-05-10 11:01:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '春天的小小鹿'}
2020-05-10 11:01:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '这样可以少烂片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.147,
 'type': 'neg',
 'user': '闲情淡志'}
2020-05-10 11:01:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#高以翔上海堡垒# 杨建南指挥官，你好',
 'essay_id': 152,
 'fav_nums': '14',
 'label': '上海堡垒',
 'score': 0.5963,
 'type': 'pos',
 'user': '格式化XXXGodfrey'}
2020-05-10 11:01:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '这对姐弟我爱了',
 'essay_id': 0,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.6325,
 'type': 'pos',
 'user': '斯诺克关哈'}
2020-05-10 11:01:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '百度鹿晗吧，陪你闯天下。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4989,
 'type': 'neg',
 'user': 'Ccckuuang'}
2020-05-10 11:01:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': '好可爱！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.879,
 'type': 'pos',
 'user': '侧耳倾听九色鹿'}
2020-05-10 11:01:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '成功你🐎呢？',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6055,
 'type': 'pos',
 'user': '我是你宽哥阿'}
2020-05-10 11:01:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '杀青快乐',
 'essay_id': 152,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.9438,
 'type': 'pos',
 'user': '路人4207'}
2020-05-10 11:01:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': ' 亮晶晶的眼睛 看谁都饱含深情',
 'essay_id': 0,
 'fav_nums': '8',
 'label': '上海堡垒',
 'score': 0.7996,
 'type': 'pos',
 'user': '路依依funnyface'}
2020-05-10 11:01:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '浙江的台风害死人了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.2048,
 'type': 'neg',
 'user': '玉鹿临风'}
2020-05-10 11:01:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4405927283314667>
{'add_time': '2019-8-16',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '极点点点点点'}
2020-05-10 11:01:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '今天看了林正英的电影，九几年电影，设备和特效落后，可放在现在，吸引力还是很大',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9802,
 'type': 'pos',
 'user': '半袖太冷'}
2020-05-10 11:01:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '表白导演！编辑！和原著作者来一波～辛苦啦！！鹿哥好好注意两天吧～',
 'essay_id': 152,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.7817,
 'type': 'pos',
 'user': '赖冠霖Lemon'}
2020-05-10 11:01:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '最后那张我有印象',
 'essay_id': 0,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.3877,
 'type': 'neg',
 'user': '橘子馒头-'}
2020-05-10 11:01:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '像个别扭的孩子'}
2020-05-10 11:01:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '烂有烂的一千万种方法，但好只有一种:演员，导演，编剧及所有工作人员赌命一般的不歇努力。中国人已经开始注重去为文化付费，电影事业是一片蓝海，只要优秀就一定会得到回报。但同时也别把人们当傻子，只要你敷衍就一定会付出代价。火炼真金，大海淘沙，想投机取巧的注定失败（除非是要洗钱）',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '两仪干也'}
2020-05-10 11:01:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4375445430873907> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4375435607440564> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '辛苦所有人啦，幕后制作也需要大家辛苦哒真的迫不及待和江洋哥哥见面了',
 'essay_id': 152,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.9999,
 'type': 'pos',
 'user': '情绪赵'}
2020-05-10 11:01:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '永远对鹿晗哥哥充满希望',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9943,
 'type': 'pos',
 'user': '猛男就要穿粉色'}
2020-05-10 11:01:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407115298681076>
{'add_time': '2019-8-19',
 'content': '这里有我',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '住在心里的鹿'}
2020-05-10 11:01:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-24',
 'content': '我只看剧情',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6182,
 'type': 'pos',
 'user': '18岁含泪守家'}
2020-05-10 11:01:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4407308995869223> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4375425235360978> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4403054646614778> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403681724019810> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '杀青快乐，期待江洋',
 'essay_id': 152,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.9731,
 'type': 'pos',
 'user': 'Mignonette钰-Lu'}
2020-05-10 11:01:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '鹿晗太帅了，舒淇也很美，期待上海堡垒，',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.9087,
 'type': 'pos',
 'user': '梅花鹿10101010'}
2020-05-10 11:01:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-23',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '哈姆斯達_陳'}
2020-05-10 11:01:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4407308995869223>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4403054646614778>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '林澜和路依依',
 'essay_id': 152,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.7722,
 'type': 'pos',
 'user': '_鹿啾啾啾M'}
2020-05-10 11:01:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '在娱乐圈这么多年了还这么害差的只有鹿宝宝了吧',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.0303,
 'type': 'neg',
 'user': '夜夏半凉·L'}
2020-05-10 11:01:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '选人说好的是他，票房不行说人家演员的也是他，人家演了一部这种烂剧本的戏对人家，有多大的损失人家演员都没说什么，他还出来扯，他拿了一部烂剧本，出来不管找谁都一样，凭什么，他拿了一部烂剧本就定义人家不适合这种类型，他一个导演，就不应该说演员什么的，自己选出来的人就应该负责到底',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9871,
 'type': 'pos',
 'user': '用户企鹅有个浪浪'}
2020-05-10 11:01:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403674623510025> (referer: None)
2020-05-10 11:01:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4399827296725811> (referer: None)
2020-05-10 11:01:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '鹿晗鹿晗想你 ',
 'essay_id': 152,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.4219,
 'type': 'neg',
 'user': 'lh红鹿角'}
2020-05-10 11:01:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '上去',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': 'dear鈺珺'}
2020-05-10 11:01:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '投完票有种做错题的感觉....直接没看D选项(以上说法都对)',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.0743,
 'type': 'neg',
 'user': '一个大胖小子哦'}
2020-05-10 11:01:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '表白鹿晗',
 'essay_id': 152,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.3013,
 'type': 'neg',
 'user': '最爱鹿鹿先森'}
2020-05-10 11:01:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '最后那张是？暖了暖了',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.7255,
 'type': 'pos',
 'user': 'dear鈺珺'}
2020-05-10 11:01:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '薛洋洋洋爱你'}
2020-05-10 11:01:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4375445430873907> (referer: None)
2020-05-10 11:01:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404010557302098> (referer: None)
2020-05-10 11:01:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403674623510025", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:01:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:01:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:01:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403674623510025> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:01:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4399827296725811", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:01:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:01:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:01:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4399827296725811> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:01:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#鹿晗# 加油',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.4095,
 'type': 'neg',
 'user': '七柒复七七'}
2020-05-10 11:01:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿哈尼，今天一定要开心哦',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.7007,
 'type': 'pos',
 'user': '猛男就要穿粉色'}
2020-05-10 11:01:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '..',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4698,
 'type': 'neg',
 'user': '费76953'}
2020-05-10 11:01:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4384862008122964> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404065821652638> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4375435607440564> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4396585540588602> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.689,
 'type': 'pos',
 'user': '马·鹿先生'}
2020-05-10 11:01:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '0809.看姐弟俩的《上海堡垒》呀  千万不要错过',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.3977,
 'type': 'neg',
 'user': 'z是因为你'}
2020-05-10 11:01:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '顶',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.549,
 'type': 'pos',
 'user': '爱摸能助28640'}
2020-05-10 11:01:32 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4403681724019810> (failed 3 times): 502 Bad Gateway
2020-05-10 11:01:32 [scrapy.core.engine] DEBUG: Crawled (502) <GET https://m.weibo.cn/detail/4403681724019810> (referer: None)
2020-05-10 11:01:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4398004557934170> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4397702894670849> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:01:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4375445430873907", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:01:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:01:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:01:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4375445430873907> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:01:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404010557302098", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:01:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:01:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:01:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404010557302098> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:01:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待江洋 期待鹿晗哥哥',
 'essay_id': 152,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.9911,
 'type': 'pos',
 'user': '社会主义_小太阳'}
2020-05-10 11:01:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': ' ',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '脆弱的静语333'}
2020-05-10 11:01:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '是妍桉呐'}
2020-05-10 11:01:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <502 https://m.weibo.cn/detail/4403681724019810>: HTTP status code is not handled or not allowed
2020-05-10 11:01:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '表白鹿晗，期待《上海堡垒》的上映',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.3443,
 'type': 'neg',
 'user': 'Fantasy--Lu'}
2020-05-10 11:01:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '期待8.9上海堡垒啦',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.3108,
 'type': 'neg',
 'user': 'M鹿M喵小乖'}
2020-05-10 11:01:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '你好',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5313,
 'type': 'pos',
 'user': '时代青年866'}
2020-05-10 11:01:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404727082906492> (referer: None)
2020-05-10 11:01:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待上海堡垒，期待江洋，大家都辛苦了！',
 'essay_id': 152,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.9362,
 'type': 'pos',
 'user': '盗版卫衣xxv'}
2020-05-10 11:01:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '江洋和林澜的暗恋',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.6864,
 'type': 'pos',
 'user': '猛男就要穿粉色'}
2020-05-10 11:01:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '这电影从开始上映出来什么见面会门票高价好像，然后有看到喷演员喷剧情喷特效，全是负面的东西。我可不是什么粉丝，这电影我还没看，只是都说差，我倒是很想看看了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.0043,
 'type': 'neg',
 'user': '闲来闲去1991'}
2020-05-10 11:01:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#鹿晗# 辛苦辛苦，期待上映',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.71,
 'type': 'pos',
 'user': '羊肉泡馍那么好吃嘛'}
2020-05-10 11:01:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '小宝贝',
 'essay_id': 0,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.8057,
 'type': 'pos',
 'user': '啊咬啊咬啊啊啊'}
2020-05-10 11:01:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '有我菜虚昆一个就够了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.3793,
 'type': 'neg',
 'user': '低调的肖邦123'}
2020-05-10 11:01:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4395495290277796> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4465298302598541> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4433448364036853> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404015137538607> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:01:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404727082906492", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:01:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:01:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:01:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404727082906492> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:01:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.689,
 'type': 'pos',
 'user': '-与你的冒险时间-'}
2020-05-10 11:01:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '鹿晗你个大猪蹄子wan'}
2020-05-10 11:01:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'kkr2_b0m'}
2020-05-10 11:01:47 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 6 pages/min), scraped 665 items (at 82 items/min)
2020-05-10 11:01:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '#鹿晗#  2019见',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.0396,
 'type': 'neg',
 'user': 'yi池清水'}
2020-05-10 11:01:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '热搜了',
 'essay_id': 0,
 'fav_nums': '7',
 'label': '上海堡垒',
 'score': 0.2107,
 'type': 'neg',
 'user': '白日梦里看风景·'}
2020-05-10 11:01:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '额额额',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6898,
 'type': 'pos',
 'user': '趁醉独饮痛0'}
2020-05-10 11:01:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '鹿晗——江洋',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.6417,
 'type': 'pos',
 'user': 'Y杨憨h'}
2020-05-10 11:01:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '小鹿的眼神这么多年了都没变',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.7193,
 'type': 'pos',
 'user': '棉花芽'}
2020-05-10 11:01:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '我觉得票房是假的！人家号称上千万甚至破亿的铁杆粉丝，不可能一个人20块钱的贡献都没有吧？如果真这样，那只能说看流量找演员的导演是傻的',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.3671,
 'type': 'neg',
 'user': '忘了谁说过'}
2020-05-10 11:01:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待期待',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.8154,
 'type': 'pos',
 'user': '2017小鹿乱撞'}
2020-05-10 11:01:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿哈尼，你永远不会让我们失望的',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1467,
 'type': 'neg',
 'user': '猛男就要穿粉色'}
2020-05-10 11:01:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '说句实话，一个士兵头发这么长?先把演技放一边，中国男兵有长头发的吗？我就没见过哪个国家的兵头发有比他长的',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1347,
 'type': 'neg',
 'user': '是zcl吗'}
2020-05-10 11:01:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404065821652638> (referer: None)
2020-05-10 11:01:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4396585540588602> (referer: None)
2020-05-10 11:01:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '回复',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.1583,
 'type': 'neg',
 'user': 'M玉佳'}
2020-05-10 11:01:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿哈尼，今天的造型一定也很好看哦',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9369,
 'type': 'pos',
 'user': '猛男就要穿粉色'}
2020-05-10 11:01:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4768,
 'type': 'neg',
 'user': '爱猫的家伙73356'}
2020-05-10 11:01:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '鹿晗啊',
 'essay_id': 152,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.4738,
 'type': 'neg',
 'user': '与你挽月色L'}
2020-05-10 11:01:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '这就是林澜和江洋的感觉啊',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.7452,
 'type': 'pos',
 'user': '猛男就要穿粉色'}
2020-05-10 11:01:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '不错',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8612,
 'type': 'pos',
 'user': 'W37341'}
2020-05-10 11:01:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404740534019910> (referer: None)
2020-05-10 11:01:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4406468905911310> (referer: None)
2020-05-10 11:01:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404065821652638", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:01:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:01:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:01:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404065821652638> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:01:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4396585540588602", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:01:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:01:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:01:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4396585540588602> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:01:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-21',
 'content': '为高以翔打Call!打到停机！！',
 'essay_id': 152,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.3598,
 'type': 'neg',
 'user': '吃点瓜瓜子'}
2020-05-10 11:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '不管娱乐圈出多少新人，鹿晗依旧是心中美好的那一个',
 'essay_id': 0,
 'fav_nums': '6',
 'label': '上海堡垒',
 'score': 0.8864,
 'type': 'pos',
 'user': '小脚丫学芭蕾'}
2020-05-10 11:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '那是因为LH不够漂亮，你看现在认识CXK的人肯定比认识LH的人多',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8776,
 'type': 'pos',
 'user': '一个人满天星'}
2020-05-10 11:02:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4375425235360978> (referer: None)
2020-05-10 11:02:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4398004557934170> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:02:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4397702894670849> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:02:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4375435607440564> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:02:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404796272587235> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '辛苦了，2019见',
 'essay_id': 152,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.6985,
 'type': 'pos',
 'user': '江洋哥哥的泳一'}
2020-05-10 11:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '营销号们就歇了吧 不是说科幻片么 难不成又是挂羊头卖狗肉 未来科幻爱情动作片',
 'essay_id': 0,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.6469,
 'type': 'pos',
 'user': '侍晓禹'}
2020-05-10 11:02:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '完美',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8234,
 'type': 'pos',
 'user': '周志松49767'}
2020-05-10 11:02:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4406338991872563> (failed 1 times): 502 Bad Gateway
2020-05-10 11:02:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402214564865663> (referer: None)
2020-05-10 11:02:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404740534019910", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404740534019910> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4406468905911310", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4406468905911310> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4375435607440564>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:02:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待上海堡垒辛苦了各位2019不见不散',
 'essay_id': 152,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.8332,
 'type': 'pos',
 'user': 'Only7sunshine'}
2020-05-10 11:02:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '喜欢这对cp那就0809来看上海堡垒',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.6213,
 'type': 'pos',
 'user': 'Babykimmy-'}
2020-05-10 11:02:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '1',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.3269,
 'type': 'neg',
 'user': '樱之恋丶雯'}
2020-05-10 11:02:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404015137538607> (referer: None)
2020-05-10 11:02:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4384862008122964> (referer: None)
2020-05-10 11:02:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4375425235360978", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4375425235360978> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '这个演员阵容，必须大爆',
 'essay_id': 152,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9256,
 'type': 'pos',
 'user': '与你挽月色L'}
2020-05-10 11:02:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'Lost_lifeless'}
2020-05-10 11:02:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '嗯',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': 'Ambition别想'}
2020-05-10 11:02:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402004941935869> (referer: None)
2020-05-10 11:02:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4402020028945728> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:02:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4465298302598541> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:02:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4395495290277796> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:02:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4427329126172353> (referer: None)
2020-05-10 11:02:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4433448364036853> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:02:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402214564865663", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402214564865663> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-21',
 'content': '高以翔，穿上制服让人无法抗拒',
 'essay_id': 152,
 'fav_nums': '4',
 'label': '上海堡垒',
 'score': 0.8188,
 'type': 'pos',
 'user': '要举高高抱高高'}
2020-05-10 11:02:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': 'L·鹿先生·U'}
2020-05-10 11:02:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-21',
 'content': '这就跟NBA一样，赢球都是球队超级球星的功劳，输球就都是教练的责任，同理电影也是，票房好是因为演员的演技好，票房低就是导演拍的烂，没办法NBA是球员统治的联盟，而电影是演员主导的产业，红花永远是红花，绿叶也永远是绿叶。',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '逆时针放逐'}
2020-05-10 11:02:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404796272587235> (referer: None)
2020-05-10 11:02:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4397702894670849> (referer: None)
2020-05-10 11:02:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4384862008122964", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4384862008122964> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404015137538607", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404015137538607> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '“',
 'essay_id': 152,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '我迷了鹿xx'}
2020-05-10 11:02:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿晗长了这么多年还是跟个小孩一样也没见老...',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.276,
 'type': 'neg',
 'user': 'InnerPeace小熊猫'}
2020-05-10 11:02:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '不错',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8612,
 'type': 'pos',
 'user': '思扬89381'}
2020-05-10 11:02:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4398004557934170> (referer: None)
2020-05-10 11:02:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4435544303773750> (referer: None)
2020-05-10 11:02:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402004941935869", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402004941935869> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4427329126172353", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4427329126172353> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '“老泪纵横  恭喜鹿爷杀青。各位都辛苦了，感谢大家一路对我们鹿晗的照顾。',
 'essay_id': 152,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9993,
 'type': 'pos',
 'user': '我迷了鹿xx'}
2020-05-10 11:02:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '太养眼了',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5182,
 'type': 'pos',
 'user': '瑞雪兆憨憨'}
2020-05-10 11:02:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '转发微博',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6439,
 'type': 'pos',
 'user': '好像白云一样飘曦'}
2020-05-10 11:02:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4435543830323654> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:02:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4412563292522163> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:02:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4433448364036853> (referer: None)
2020-05-10 11:02:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4406338991872563> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:02:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4395495290277796> (referer: None)
2020-05-10 11:02:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404796272587235", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404796272587235> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4397702894670849", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4397702894670849> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': ' 各位主创们辛苦了，期待电影上映，江洋',
 'essay_id': 152,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9358,
 'type': 'pos',
 'user': 'L小果的少女心7'}
2020-05-10 11:02:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '姐姐好美',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9664,
 'type': 'pos',
 'user': '洪小二呀'}
2020-05-10 11:02:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '好好拍电影，你用一条狗都能拍的好，比如忠犬八公！',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9639,
 'type': 'pos',
 'user': '起个名字要用好长时间'}
2020-05-10 11:02:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4465298302598541> (referer: None)
2020-05-10 11:02:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4435563752961334> (referer: None)
2020-05-10 11:02:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4398004557934170", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4398004557934170> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4435544303773750", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4435544303773750> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '我们江洋小哥哥帅爆了',
 'essay_id': 152,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.99,
 'type': 'pos',
 'user': '歪歪木子果'}
2020-05-10 11:02:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '宝贝好害羞',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8638,
 'type': 'pos',
 'user': '酒酿葡萄·'}
2020-05-10 11:02:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '应该是剧情不好  ，非常假',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.3109,
 'type': 'neg',
 'user': '萌萌哒小蜜蜂love'}
2020-05-10 11:02:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4402020028945728> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:02:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4441207776348227> (referer: None)
2020-05-10 11:02:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4412563292522163> (referer: None)
2020-05-10 11:02:54 [scrapy.extensions.logstats] INFO: Crawled 68 pages (at 20 pages/min), scraped 707 items (at 42 items/min)
2020-05-10 11:02:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4433448364036853", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:02:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:02:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:02:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4433448364036853> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:02:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4395495290277796", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4395495290277796> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待老鹿，期待上海堡垒',
 'essay_id': 152,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.7449,
 'type': 'pos',
 'user': 'A大胖姑娘'}
2020-05-10 11:03:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '太可爱了',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6663,
 'type': 'pos',
 'user': '初阡联合创始_西瓜矮姨'}
2020-05-10 11:03:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '每个元素都很重要',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8602,
 'type': 'pos',
 'user': '仃脩儁'}
2020-05-10 11:03:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4435597277669538> (referer: None)
2020-05-10 11:03:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4435571575228528> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4465298302598541", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4465298302598541> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4435563752961334", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4435563752961334> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '期待江洋',
 'essay_id': 152,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.7053,
 'type': 'pos',
 'user': '骆寒声'}
2020-05-10 11:03:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': ' 早安',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.7666,
 'type': 'pos',
 'user': '7_luHanhan'}
2020-05-10 11:03:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '流浪地球成功打开了中国科幻电影的大门，上海堡垒成功关上了。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9995,
 'type': 'pos',
 'user': '剑殇199010'}
2020-05-10 11:03:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402020028945728> (referer: None)
2020-05-10 11:03:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4441207776348227", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4441207776348227> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4412563292522163", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4412563292522163> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '2019电影院等待江洋',
 'essay_id': 152,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.42,
 'type': 'neg',
 'user': '_______茫茫吖'}
2020-05-10 11:03:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '可爱啊',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8089,
 'type': 'pos',
 'user': 'Super7i'}
2020-05-10 11:03:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '故事情节好十分重要。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9037,
 'type': 'pos',
 'user': '君爷爷2018'}
2020-05-10 11:03:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4435571575228528> (referer: None)
2020-05-10 11:03:22 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4406338991872563> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4435543830323654> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4435597277669538", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4435597277669538> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2019-7-18',
 'content': '我还挺期待舒淇的',
 'essay_id': 152,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8601,
 'type': 'pos',
 'user': 'ykiiiii_7'}
2020-05-10 11:03:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '弄个电影宣传就能占热搜好几个小时的人除了老鹿也很少人能做到了吧',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.062,
 'type': 'neg',
 'user': 'Lhu哎'}
2020-05-10 11:03:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '应该怪粉丝太拉垮了，偶像演的电影怎么能不三四五刷呢',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8312,
 'type': 'pos',
 'user': '咸鱼王-快使用水溅跃23333'}
2020-05-10 11:03:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403873324096037> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403874120948000> (referer: None)
2020-05-10 11:03:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4406338991872563>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402020028945728", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402020028945728> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2019-7-17',
 'content': ' 终于等到上映，当时觉得2019好遥远啊',
 'essay_id': 152,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6811,
 'type': 'pos',
 'user': '兔兔-雪后初晴'}
2020-05-10 11:03:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '帅爆我哥',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.7394,
 'type': 'pos',
 'user': '陳阿瓜H'}
2020-05-10 11:03:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '真假粉丝一目便知',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8168,
 'type': 'pos',
 'user': '1kuo許願樹'}
2020-05-10 11:03:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4411838504196586> (referer: None)
2020-05-10 11:03:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403689148021264> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4435571575228528", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4435571575228528> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-20',
 'content': '拍完了才知道所有演员',
 'essay_id': 152,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.926,
 'type': 'pos',
 'user': '小鹿历险记'}
2020-05-10 11:03:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '鹿晗还是那么可爱ớ ₃ờ',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.7718,
 'type': 'pos',
 'user': 'K9tkk'}
2020-05-10 11:03:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '转发微博',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6439,
 'type': 'pos',
 'user': '桂悃178120'}
2020-05-10 11:03:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404796272587235> (failed 1 times): 502 Bad Gateway
2020-05-10 11:03:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403874120948000", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403874120948000> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4187122292937189>
{'add_time': '2017-12-21',
 'content': '  好帅！好棒！👍🌷（扬建南指挥官）',
 'essay_id': 152,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9366,
 'type': 'pos',
 'user': '安琪稻花飘香'}
2020-05-10 11:03:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '感觉好久没见小鹿了，看到他依然很喜欢他',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.6394,
 'type': 'pos',
 'user': '小脚丫学芭蕾'}
2020-05-10 11:03:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '图题',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '茜雅y_'}
2020-05-10 11:03:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4411838504196586", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4411838504196586> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '鹿晗最帅',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6185,
 'type': 'pos',
 'user': '偶像太帅怎么办M鹿M'}
2020-05-10 11:03:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '转发微博',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6439,
 'type': 'pos',
 'user': '日系时尚女装巩'}
2020-05-10 11:03:50 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://m.weibo.cn/detail/4435543830323654> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:50 [scrapy.extensions.logstats] INFO: Crawled 73 pages (at 5 pages/min), scraped 730 items (at 23 items/min)
2020-05-10 11:03:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '俊男靓女的搭配就是养眼',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9165,
 'type': 'pos',
 'user': '7_lucky_7'}
2020-05-10 11:03:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。。',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4768,
 'type': 'neg',
 'user': '木槿鸢缘'}
2020-05-10 11:03:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403873324096037> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://m.weibo.cn/detail/4435543830323654>
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    defer.returnValue((yield download_func(request=request, spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:03:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '原来芭莎之夜就有交集啊',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.6065,
 'type': 'pos',
 'user': '唯有鹿哥知心'}
2020-05-10 11:03:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '666',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '我不shi好仁'}
2020-05-10 11:03:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': ' 期待你俩的感情戏呢！',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9584,
 'type': 'pos',
 'user': '憨憨归来7777777'}
2020-05-10 11:03:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '不错',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8612,
 'type': 'pos',
 'user': '世界太假我们太傻5366'}
2020-05-10 11:03:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '冲这两人这电影我要去看了！',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.814,
 'type': 'pos',
 'user': 'M绿杨烟外M'}
2020-05-10 11:03:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '看综合实力，有些片子，演员表演不行但一样大卖，因为题材新颖，比如致青春，有些片子投资很小，但是演员出彩，情节刘畅舒服比如泰囧，有些特技并不完美，但是给国人心灵震撼，开创先和，比如流浪地球。 '
            '有些片子在恰当的时候点燃了人民心中的情感比如战狼2， 当然制作精良是基本面',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 1.0,
 'type': 'pos',
 'user': '警察叔叔亨特朱'}
2020-05-10 11:03:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿哈尼要一直开心，像昨天一样知道吗？你是小王子啊，满身富贵懒察觉',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9629,
 'type': 'pos',
 'user': '猛男就要穿粉色'}
2020-05-10 11:03:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '哈哈哈',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.8684,
 'type': 'pos',
 'user': 'Ambrose·Sze'}
2020-05-10 11:03:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403689148021264> (referer: None)
2020-05-10 11:03:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '忽然get到鹿晗的颜？？',
 'essay_id': 0,
 'fav_nums': '3',
 'label': '上海堡垒',
 'score': 0.7188,
 'type': 'pos',
 'user': 'kiwiiiii啊'}
2020-05-10 11:03:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '说不过我还会',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4655,
 'type': 'neg',
 'user': '单线告别72407'}
2020-05-10 11:03:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404796272587235> (referer: None)
2020-05-10 11:03:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿晗好帅',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.4477,
 'type': 'neg',
 'user': '我的鹿角怎么歪了呢'}
2020-05-10 11:03:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '好看',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.7112,
 'type': 'pos',
 'user': '子涵201407'}
2020-05-10 11:03:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404836138926384> (referer: None)
2020-05-10 11:03:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403444049308888> (referer: None)
2020-05-10 11:03:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403689148021264", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:03:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:03:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:03:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403689148021264> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:03:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '可爱帅鹿',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9796,
 'type': 'pos',
 'user': '长发及腰热不热530'}
2020-05-10 11:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '哦',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '小迷哥585'}
2020-05-10 11:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404802588931496> (referer: None)
2020-05-10 11:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404806296333820> (referer: None)
2020-05-10 11:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403679215837077> (referer: None)
2020-05-10 11:03:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404796272587235", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404796272587235> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '都是帅哥美女',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.4645,
 'type': 'neg',
 'user': '一鹿长伴520'}
2020-05-10 11:04:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '！',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '开心铃铛乐'}
2020-05-10 11:04:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403771704973254> (referer: None)
2020-05-10 11:04:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403873324096037> (referer: None)
2020-05-10 11:04:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404740534019910> (referer: None)
2020-05-10 11:04:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404366964069727> (referer: None)
2020-05-10 11:04:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405124632294524> (referer: None)
2020-05-10 11:04:04 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404836138926384", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404836138926384> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403444049308888", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403444049308888> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '哇哇哇',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '七支小布丁'}
2020-05-10 11:04:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '绝凡燚惘'}
2020-05-10 11:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403792152119451> (referer: None)
2020-05-10 11:04:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404023744036666> (referer: None)
2020-05-10 11:04:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404802588931496", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404802588931496> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404806296333820", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404806296333820> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403679215837077", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403679215837077> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '我爱帅哥美女',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.4396,
 'type': 'neg',
 'user': '眼瞎患者十级'}
2020-05-10 11:04:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '好',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6559,
 'type': 'pos',
 'user': '毛哥精神209'}
2020-05-10 11:04:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403900172318191> (referer: None)
2020-05-10 11:04:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403771704973254", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403771704973254> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403873324096037", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403873324096037> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:37 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404740534019910", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404740534019910> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404366964069727", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404366964069727> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405124632294524", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405124632294524> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '漂亮姐姐和漂亮哥哥',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9998,
 'type': 'pos',
 'user': 'Andy小朋友的糖果'}
2020-05-10 11:04:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '其实上海堡垒电影，在结尾 让蔡徐坤，跳一段鸡你太美，票房也不会这么差',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9916,
 'type': 'pos',
 'user': '撒旦的告白'}
2020-05-10 11:04:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404038558331069> (failed 1 times): 504 Gateway Time-out
2020-05-10 11:04:52 [scrapy.extensions.logstats] INFO: Crawled 88 pages (at 15 pages/min), scraped 754 items (at 24 items/min)
2020-05-10 11:04:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403792152119451", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:04:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:04:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:04:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403792152119451> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:04:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404023744036666", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404023744036666> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '帅气姐弟哈哈哈哈',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9845,
 'type': 'pos',
 'user': '带着鹿角的斑马'}
2020-05-10 11:05:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '开心6153203856'}
2020-05-10 11:05:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403900172318191", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403900172318191> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '姐弟太有感觉了',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.293,
 'type': 'neg',
 'user': '猛男就要穿粉色'}
2020-05-10 11:05:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '转发微博',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.6439,
 'type': 'pos',
 'user': '熊关袂826276'}
2020-05-10 11:05:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403863572329843> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:05:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '8.9 不见不散',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.2308,
 'type': 'neg',
 'user': '猛男就要穿粉色'}
2020-05-10 11:05:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '好吃',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5732,
 'type': 'pos',
 'user': '血羽魔200406'}
2020-05-10 11:05:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '回复为图片',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.1911,
 'type': 'neg',
 'user': '辣炒小兔叽'}
2020-05-10 11:05:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '流量当道，烂片洗钱',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.0512,
 'type': 'neg',
 'user': '天仙之主-帝都'}
2020-05-10 11:05:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '江洋林澜也太好磕了吧',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.1579,
 'type': 'neg',
 'user': '白日梦里看风景·'}
2020-05-10 11:05:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '。',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.5262,
 'type': 'pos',
 'user': '寒龙神烽'}
2020-05-10 11:05:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '啊啊啊啊啊啊啊啊啊啊啊啊，鹿哥好帅，8.9号见江洋',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9967,
 'type': 'pos',
 'user': '冷暖自知112334'}
2020-05-10 11:05:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4407406534155151>
{'add_time': '2019-8-20',
 'content': '成功的关键是千万不要用小鲜肉当主角，现在我的认知已经形成了  小鲜肉主角=烂片 的定式了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9084,
 'type': 'pos',
 'user': '岳一平1997'}
2020-05-10 11:05:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '真好看两人',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.6873,
 'type': 'pos',
 'user': '樱子hhhh'}
2020-05-10 11:05:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '哈哈哈哈哈哈哈哈哈',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.9957,
 'type': 'pos',
 'user': '春风十里不如一鹿伴你'}
2020-05-10 11:05:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403852478615102> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:05:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '好爱',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8361,
 'type': 'pos',
 'user': '白日梦里看风景·'}
2020-05-10 11:05:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404038558331069> (referer: None)
2020-05-10 11:05:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404046062637721> (referer: None)
2020-05-10 11:05:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '作为粉丝竟然是在热搜上存图的，我打我自己',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.1394,
 'type': 'neg',
 'user': '共渡冒险时间'}
2020-05-10 11:05:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404070552678409> (referer: None)
2020-05-10 11:05:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404066907941403> (referer: None)
2020-05-10 11:05:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403863572329843> (referer: None)
2020-05-10 11:05:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '超级可爱啊啊啊',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.8924,
 'type': 'pos',
 'user': '陸吷亓廿'}
2020-05-10 11:05:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404603078166457> (referer: None)
2020-05-10 11:05:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404508924565953> (referer: None)
2020-05-10 11:05:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404507330975576> (failed 1 times): 502 Bad Gateway
2020-05-10 11:05:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404038558331069", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404038558331069> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404046062637721", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404046062637721> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-15',
 'content': '小鹿今晚帅死了',
 'essay_id': 0,
 'fav_nums': '5',
 'label': '上海堡垒',
 'score': 0.8118,
 'type': 'pos',
 'user': '7桤林94'}
2020-05-10 11:05:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404070552678409", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404070552678409> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404591229257914> (referer: None)
2020-05-10 11:05:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4406749098368008> (referer: None)
2020-05-10 11:05:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403852478615102> (referer: None)
2020-05-10 11:05:28 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://m.weibo.cn/detail/4411371489400160> (referer: None)
2020-05-10 11:05:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403863572329843", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403863572329843> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404066907941403", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404066907941403> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': ' 哈哈，小傻鹿都不敢看舒淇',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.178,
 'type': 'neg',
 'user': '旺崽小猪熊'}
2020-05-10 11:05:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404557608505508> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:05:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405870034959232> (referer: None)
2020-05-10 11:05:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4419980261029887> (referer: None)
2020-05-10 11:05:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404507330975576> (referer: None)
2020-05-10 11:05:37 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404603078166457", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404603078166457> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404508924565953", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404508924565953> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://m.weibo.cn/detail/4411371489400160>: HTTP status code is not handled or not allowed
2020-05-10 11:05:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿哥一直这么优秀 真开心',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9412,
 'type': 'pos',
 'user': 'M鸥M鹿晗'}
2020-05-10 11:05:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4412972518098942> (referer: None)
2020-05-10 11:05:47 [scrapy.extensions.logstats] INFO: Crawled 103 pages (at 15 pages/min), scraped 774 items (at 20 items/min)
2020-05-10 11:05:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404591229257914", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404591229257914> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4406749098368008", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:05:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:05:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:05:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4406749098368008> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:05:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403852478615102", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403852478615102> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '舒淇姐姐美美哒',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9866,
 'type': 'pos',
 'user': 'MM安琪MM'}
2020-05-10 11:06:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405870034959232", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405870034959232> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4419980261029887", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4419980261029887> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:11 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404507330975576", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404507330975576> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '男神很帅期待0809上海堡垒',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.7116,
 'type': 'pos',
 'user': 'M傻狍子的冰美式'}
2020-05-10 11:06:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4412972518098942", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4412972518098942> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '舒淇这会真漂亮',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.8809,
 'type': 'pos',
 'user': '小凳2'}
2020-05-10 11:06:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404557608505508> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:06:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4412950917515779> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:06:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '哈哈哈舒淇姐姐气场太强，我家小鹿不好意思',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.848,
 'type': 'pos',
 'user': '鹿长生吖'}
2020-05-10 11:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '美女姐姐，帅弟弟',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9714,
 'type': 'pos',
 'user': '-L-晶晶'}
2020-05-10 11:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '加油加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9878,
 'type': 'pos',
 'user': '一朵云中的蒲公英'}
2020-05-10 11:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '加油加油',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.9878,
 'type': 'pos',
 'user': '云层3656'}
2020-05-10 11:06:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '可爱，好好休息，你最近太累了',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5583,
 'type': 'pos',
 'user': '猛男就要穿粉色'}
2020-05-10 11:06:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '我的鹿晗啊啊啊',
 'essay_id': 0,
 'fav_nums': '1',
 'label': '上海堡垒',
 'score': 0.7086,
 'type': 'pos',
 'user': 'ILEeeeYanKai'}
2020-05-10 11:06:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4412101940417342> (referer: None)
2020-05-10 11:06:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '鹿哈尼，一会儿又能见到啦',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.4262,
 'type': 'neg',
 'user': '猛男就要穿粉色'}
2020-05-10 11:06:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4412086283116939> (referer: None)
2020-05-10 11:06:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '❤️//',
 'essay_id': 0,
 'fav_nums': 0,
 'label': '上海堡垒',
 'score': 0.5,
 'type': 'neg',
 'user': '黃小雅乖乖'}
2020-05-10 11:06:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4412101940417342", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4412101940417342> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/detail/4383519922827650>
{'add_time': '2019-6-16',
 'content': '感觉舒淇，白百合，都是那种很耐看的人，越看越好看。',
 'essay_id': 0,
 'fav_nums': '2',
 'label': '上海堡垒',
 'score': 0.9801,
 'type': 'pos',
 'user': '山田心的我'}
2020-05-10 11:06:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404557608505508> (referer: None)
2020-05-10 11:06:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4394460345504252> (referer: None)
2020-05-10 11:06:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4412067538404694> (referer: None)
2020-05-10 11:06:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4412950917515779> (referer: None)
2020-05-10 11:06:29 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://m.weibo.cn/detail/4412015420157086> (referer: None)
2020-05-10 11:06:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4412086283116939", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4412086283116939> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:36 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://m.weibo.cn/detail/4412015420157086> (referer: None)
2020-05-10 11:06:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4412005131382201> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:06:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://m.weibo.cn/detail/4412015420157086>: HTTP status code is not handled or not allowed
2020-05-10 11:06:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404557608505508", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404557608505508> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4394460345504252", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4394460345504252> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4412067538404694", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4412067538404694> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4394460345504252> (referer: None)
2020-05-10 11:06:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4420518063320973> (referer: None)
2020-05-10 11:06:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403164562509447> (failed 1 times): 502 Bad Gateway
2020-05-10 11:06:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403138272324816> (referer: None)
2020-05-10 11:06:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403123680256383> (referer: None)
2020-05-10 11:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4412950917515779", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:06:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4412950917515779> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:06:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://m.weibo.cn/detail/4412015420157086>: HTTP status code is not handled or not allowed
2020-05-10 11:06:55 [scrapy.extensions.logstats] INFO: Crawled 115 pages (at 12 pages/min), scraped 786 items (at 12 items/min)
2020-05-10 11:06:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4411347452116935> (referer: None)
2020-05-10 11:06:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4398241896318256> (failed 1 times): 504 Gateway Time-out
2020-05-10 11:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4394460345504252", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4394460345504252> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4420518063320973", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4420518063320973> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403138272324816", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403138272324816> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403123680256383", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403123680256383> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404881551314924> (referer: None)
2020-05-10 11:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403164562509447> (referer: None)
2020-05-10 11:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4398241896318256> (referer: None)
2020-05-10 11:07:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4412005131382201> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:07:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4411347452116935", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4411347452116935> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403804696809920> (referer: None)
2020-05-10 11:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4412005131382201> (referer: None)
2020-05-10 11:07:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4413582332589990> (referer: None)
2020-05-10 11:07:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404881551314924", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404881551314924> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403164562509447", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403164562509447> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4398241896318256", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4398241896318256> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4382438010889980> (referer: None)
2020-05-10 11:07:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4410753710532022> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:07:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403804696809920", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403804696809920> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4412005131382201", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4412005131382201> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4413582332589990", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4413582332589990> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:47 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://m.weibo.cn/detail/4410753710532022> (referer: None)
2020-05-10 11:07:47 [scrapy.extensions.logstats] INFO: Crawled 124 pages (at 9 pages/min), scraped 786 items (at 0 items/min)
2020-05-10 11:07:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4382438010889980", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4382438010889980> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4400735481573968> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:07:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://m.weibo.cn/detail/4410753710532022>: HTTP status code is not handled or not allowed
2020-05-10 11:07:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4382485699971755> (referer: None)
2020-05-10 11:07:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404192783736369> (referer: None)
2020-05-10 11:07:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4382485699971755> (referer: None)
2020-05-10 11:07:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404408248868695> (referer: None)
2020-05-10 11:07:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4382485699971755", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:07:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:07:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:07:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4382485699971755> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:07:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404375889624678> (referer: None)
2020-05-10 11:07:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404411537162965> (referer: None)
2020-05-10 11:07:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404924424835959> (referer: None)
2020-05-10 11:07:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4386260774793890> (referer: None)
2020-05-10 11:07:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404192783736369", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404192783736369> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403145331265942> (referer: None)
2020-05-10 11:08:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404414838083124> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2020-05-10 11:08:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4382485699971755", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4382485699971755> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404408248868695", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404408248868695> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404375889624678", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404375889624678> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404411537162965", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404411537162965> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:21 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404924424835959", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404924424835959> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404237641617501> (referer: None)
2020-05-10 11:08:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402715075530232> (referer: None)
2020-05-10 11:08:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4400735481573968> (referer: None)
2020-05-10 11:08:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404443783087772> (referer: None)
2020-05-10 11:08:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404194339710721> (referer: None)
2020-05-10 11:08:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4386260774793890", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4386260774793890> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402933376030267> (referer: None)
2020-05-10 11:08:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403145331265942", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403145331265942> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404237641617501", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404237641617501> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404937151202383> (failed 1 times): 502 Bad Gateway
2020-05-10 11:08:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4405179937867839> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:08:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404414838083124> (referer: None)
2020-05-10 11:08:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402715075530232", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402715075530232> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4400735481573968", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4400735481573968> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404443783087772", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404443783087772> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404194339710721", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:08:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:08:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:08:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404194339710721> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:08:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404224940964766> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:08:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402933376030267", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402933376030267> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:04 [scrapy.extensions.logstats] INFO: Crawled 140 pages (at 16 pages/min), scraped 786 items (at 0 items/min)
2020-05-10 11:09:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404895073089384> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:09:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4404920617174209> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:09:04 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404414838083124", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404414838083124> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404937151202383> (referer: None)
2020-05-10 11:09:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404809589724026> (referer: None)
2020-05-10 11:09:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404809589724026> (referer: None)
2020-05-10 11:09:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404224940964766> (referer: None)
2020-05-10 11:09:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404809589724026> (referer: None)
2020-05-10 11:09:08 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404937151202383", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404937151202383> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404895073089384> (referer: None)
2020-05-10 11:09:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4472312441480226> (referer: None)
2020-05-10 11:09:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4445727071305724> (referer: None)
2020-05-10 11:09:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4450560629813885> (referer: None)
2020-05-10 11:09:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4407406534155151> (referer: None)
2020-05-10 11:09:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4453795063054257> (referer: None)
2020-05-10 11:09:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404809589724026", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404809589724026> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404809589724026", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404809589724026> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404224940964766", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404224940964766> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404809589724026", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404809589724026> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4451216975240885> (referer: None)
2020-05-10 11:09:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4446182220666437> (referer: None)
2020-05-10 11:09:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4406016861457170> (referer: None)
2020-05-10 11:09:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403343164160249> (referer: None)
2020-05-10 11:09:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403336755233190> (referer: None)
2020-05-10 11:09:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4409814555795789> (referer: None)
2020-05-10 11:09:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404895073089384", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404895073089384> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4472312441480226", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4472312441480226> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4445727071305724", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4445727071305724> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4450560629813885", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4450560629813885> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4407406534155151", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4407406534155151> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4453795063054257", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4453795063054257> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404920617174209> (referer: None)
2020-05-10 11:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405179937867839> (referer: None)
2020-05-10 11:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4408246653225529> (referer: None)
2020-05-10 11:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4408100184112943> (referer: None)
2020-05-10 11:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4406402254412841> (referer: None)
2020-05-10 11:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404743503629318> (referer: None)
2020-05-10 11:09:53 [scrapy.extensions.logstats] INFO: Crawled 163 pages (at 23 pages/min), scraped 786 items (at 0 items/min)
2020-05-10 11:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4451216975240885", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:09:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4451216975240885> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4446182220666437", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4446182220666437> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4406016861457170", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4406016861457170> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403343164160249", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403343164160249> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403336755233190", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403336755233190> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4409814555795789", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4409814555795789> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4402604618836047> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:10:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404920617174209", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404920617174209> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:21 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405179937867839", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405179937867839> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4408246653225529", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4408246653225529> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4408100184112943", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4408100184112943> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4406402254412841", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4406402254412841> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:37 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404743503629318", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404743503629318> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403682785386304> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:10:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4401872657543683> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:10:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402604618836047> (referer: None)
2020-05-10 11:10:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403335970691867> (referer: None)
2020-05-10 11:10:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4401571502271773> (referer: None)
2020-05-10 11:10:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403682785386304> (referer: None)
2020-05-10 11:10:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404800294879498> (referer: None)
2020-05-10 11:10:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404817935665357> (referer: None)
2020-05-10 11:10:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4401872657543683> (referer: None)
2020-05-10 11:10:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402604618836047", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402604618836047> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403139534642809> (referer: None)
2020-05-10 11:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405638371322420> (referer: None)
2020-05-10 11:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404838160786057> (referer: None)
2020-05-10 11:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404892770364933> (referer: None)
2020-05-10 11:10:46 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://m.weibo.cn/detail/4404841771773774> (referer: None)
2020-05-10 11:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404838160786057> (referer: None)
2020-05-10 11:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405138830046366> (referer: None)
2020-05-10 11:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404929781463048> (referer: None)
2020-05-10 11:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403335970691867", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403335970691867> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4401571502271773", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4401571502271773> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403682785386304", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:10:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:10:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:10:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403682785386304> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:10:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404800294879498", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404800294879498> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404817935665357", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404817935665357> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4401872657543683", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4401872657543683> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404040316148100> (referer: None)
2020-05-10 11:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403176444269034> (referer: None)
2020-05-10 11:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403133348223837> (referer: None)
2020-05-10 11:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402797459755433> (referer: None)
2020-05-10 11:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4401983441902863> (referer: None)
2020-05-10 11:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4397655968840412> (referer: None)
2020-05-10 11:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4397919027166456> (referer: None)
2020-05-10 11:11:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://m.weibo.cn/detail/4404841771773774>: HTTP status code is not handled or not allowed
2020-05-10 11:11:10 [scrapy.extensions.logstats] INFO: Crawled 185 pages (at 22 pages/min), scraped 786 items (at 0 items/min)
2020-05-10 11:11:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403139534642809", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403139534642809> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405638371322420", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405638371322420> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404838160786057", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404838160786057> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404892770364933", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404892770364933> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405138830046366", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405138830046366> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404929781463048", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404929781463048> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404838160786057", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404838160786057> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4412389681868195> (failed 1 times): 504 Gateway Time-out
2020-05-10 11:11:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4397573240847216> (referer: None)
2020-05-10 11:11:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4400881909146872> (referer: None)
2020-05-10 11:11:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404040316148100", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404040316148100> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403176444269034", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403176444269034> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403133348223837", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403133348223837> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402797459755433", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402797459755433> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4401983441902863", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:11:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:11:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:11:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4401983441902863> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:11:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4397655968840412", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4397655968840412> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4397919027166456", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4397919027166456> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:07 [scrapy.extensions.logstats] INFO: Crawled 187 pages (at 2 pages/min), scraped 786 items (at 0 items/min)
2020-05-10 11:12:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4405594733594628> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:12:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4397573240847216", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4397573240847216> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:11 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4400881909146872", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4400881909146872> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405594733594628> (referer: None)
2020-05-10 11:12:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4406325624315366> (referer: None)
2020-05-10 11:12:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405603314716954> (referer: None)
2020-05-10 11:12:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405578925851032> (referer: None)
2020-05-10 11:12:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405940365599067> (referer: None)
2020-05-10 11:12:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405898162505748> (referer: None)
2020-05-10 11:12:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405602887426751> (referer: None)
2020-05-10 11:12:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405594733594628", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405594733594628> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403005723996156> (referer: None)
2020-05-10 11:12:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402406944913719> (referer: None)
2020-05-10 11:12:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4396488475729308> (referer: None)
2020-05-10 11:12:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402729709017473> (referer: None)
2020-05-10 11:12:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4396850456706925> (referer: None)
2020-05-10 11:12:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4406325624315366", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4406325624315366> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405603314716954", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405603314716954> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405578925851032", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405578925851032> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405898162505748", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405898162505748> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405602887426751", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405602887426751> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405940365599067", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405940365599067> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4388654753041136> (referer: None)
2020-05-10 11:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4388546666211534> (referer: None)
2020-05-10 11:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4396646437561907> (referer: None)
2020-05-10 11:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4388239211077125> (referer: None)
2020-05-10 11:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4413604566538225> (referer: None)
2020-05-10 11:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4391541264668673> (referer: None)
2020-05-10 11:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403335497493242> (referer: None)
2020-05-10 11:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4412389681868195> (referer: None)
2020-05-10 11:12:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403005723996156", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403005723996156> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402406944913719", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402406944913719> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4396488475729308", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:12:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:12:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:12:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4396488475729308> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:12:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4396850456706925", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4396850456706925> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402729709017473", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402729709017473> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403834333810454> (referer: None)
2020-05-10 11:13:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403471039858581> (referer: None)
2020-05-10 11:13:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403444679171144> (referer: None)
2020-05-10 11:13:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4401627945447800> (referer: None)
2020-05-10 11:13:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4401603077327723> (referer: None)
2020-05-10 11:13:04 [scrapy.extensions.logstats] INFO: Crawled 212 pages (at 25 pages/min), scraped 786 items (at 0 items/min)
2020-05-10 11:13:04 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4388654753041136", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4388654753041136> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:08 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4388546666211534", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4388546666211534> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4396646437561907", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4396646437561907> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4388239211077125", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4388239211077125> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4413604566538225", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4413604566538225> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4391541264668673", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4391541264668673> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403335497493242", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403335497493242> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4412389681868195", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4412389681868195> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403378694026240> (referer: None)
2020-05-10 11:13:37 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403834333810454", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403834333810454> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403471039858581", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403471039858581> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403444679171144", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403444679171144> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4401627945447800", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4401627945447800> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4401603077327723", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:13:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:13:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:13:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4401603077327723> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:13:57 [scrapy.extensions.logstats] INFO: Crawled 213 pages (at 1 pages/min), scraped 786 items (at 0 items/min)
2020-05-10 11:13:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4405938121528398> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:13:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4402351429317158> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2020-05-10 11:13:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403378694026240", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403378694026240> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4406430633448258> (referer: None)
2020-05-10 11:14:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403507925077987> (referer: None)
2020-05-10 11:14:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4386826871216727> (referer: None)
2020-05-10 11:14:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4400800052765216> (referer: None)
2020-05-10 11:14:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4400455675685812> (referer: None)
2020-05-10 11:14:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4406430633448258", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4406430633448258> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4187078201214691> (referer: None)
2020-05-10 11:14:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4402351429317158> (referer: None)
2020-05-10 11:14:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4151281993875148> (referer: None)
2020-05-10 11:14:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4154191250900333> (referer: None)
2020-05-10 11:14:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4405938121528398> (referer: None)
2020-05-10 11:14:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404760750802372> (referer: None)
2020-05-10 11:14:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403507925077987", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403507925077987> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4386826871216727", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4386826871216727> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4400800052765216", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4400800052765216> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4400455675685812", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4400455675685812> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4187125069016843> (referer: None)
2020-05-10 11:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4187128575897338> (referer: None)
2020-05-10 11:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404929948974906> (referer: None)
2020-05-10 11:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4404282210063950> (referer: None)
2020-05-10 11:14:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://m.weibo.cn/detail/4403828659384594> (failed 1 times): 502 Bad Gateway
2020-05-10 11:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403272342935671> (referer: None)
2020-05-10 11:14:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4187078201214691", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4187078201214691> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4402351429317158", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4402351429317158> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4154191250900333", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4154191250900333> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4151281993875148", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4151281993875148> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4405938121528398", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4405938121528398> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404760750802372", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404760750802372> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4406574472409783> (referer: None)
2020-05-10 11:14:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/detail/4403828659384594> (referer: None)
2020-05-10 11:14:46 [scrapy.extensions.logstats] INFO: Crawled 231 pages (at 18 pages/min), scraped 786 items (at 0 items/min)
2020-05-10 11:14:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4187125069016843", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4187125069016843> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4187128575897338", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4187128575897338> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404282210063950", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:14:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:14:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:14:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404282210063950> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:14:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403272342935671", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:15:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:15:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:15:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403272342935671> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:15:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4404929948974906", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:15:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:15:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:15:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4404929948974906> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:15:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4406574472409783", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:15:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:15:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:15:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4406574472409783> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:15:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60001/session/e7f5f6d3603a2caed104f2b6543975b2/url {"url": "https://m.weibo.cn/detail/4403828659384594", "sessionId": "e7f5f6d3603a2caed104f2b6543975b2"}
2020-05-10 11:15:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60001 "POST /session/e7f5f6d3603a2caed104f2b6543975b2/url HTTP/1.1" 200 268
2020-05-10 11:15:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2020-05-10 11:15:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/detail/4403828659384594> (referer: None)
Traceback (most recent call last):
  File "e:\software\python3.7.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "e:\software\python3.7.6\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "e:\software\python3.7.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\GitHubCode\Code\Python\Django\Text_Analysis\gerapy\projects\weibo\weibo\spiders\weibofilm.py", line 84, in parse
    self.web.get(response.url)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "e:\software\python3.7.6\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=72.0.3626.121)
  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.17134 x86_64)

2020-05-10 11:15:14 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-10 11:15:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 120,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 120,
 'downloader/request_bytes': 158027,
 'downloader/request_count': 364,
 'downloader/request_method_count/GET': 364,
 'downloader/response_bytes': 1392071,
 'downloader/response_count': 244,
 'downloader/response_status_count/200': 225,
 'downloader/response_status_count/400': 5,
 'downloader/response_status_count/502': 10,
 'downloader/response_status_count/504': 4,
 'elapsed_time_seconds': 1348.515211,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 10, 3, 15, 14, 817671),
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/400': 5,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 786,
 'log_count/DEBUG': 2283,
 'log_count/ERROR': 222,
 'log_count/INFO': 35,
 'log_count/WARNING': 1,
 'response_received_count': 231,
 'retry/count': 114,
 'retry/max_reached': 20,
 'retry/reason_count/502 Bad Gateway': 9,
 'retry/reason_count/504 Gateway Time-out': 4,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 101,
 'scheduler/dequeued': 364,
 'scheduler/dequeued/memory': 364,
 'scheduler/enqueued': 364,
 'scheduler/enqueued/memory': 364,
 'spider_exceptions/WebDriverException': 203,
 'start_time': datetime.datetime(2020, 5, 10, 2, 52, 46, 302460)}
2020-05-10 11:15:14 [scrapy.core.engine] INFO: Spider closed (finished)
